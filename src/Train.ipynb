{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4d95fac-ac1d-473c-ab96-650f76e6aaf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Code to convert this notebook to .py if you want to run it via command line or with Slurm\n",
    "# from subprocess import call\n",
    "# command = \"jupyter nbconvert Train.ipynb --to python\"\n",
    "# call(command,shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f0f4f3",
   "metadata": {},
   "source": [
    "# Import packages & functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bad764b-45c1-45ce-a716-8d055e09821a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-29 17:14:18,149] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "LOCAL RANK  0\n",
      "[2023-08-29 17:14:20,083] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[2023-08-29 17:14:20,084] [INFO] [comm.py:616:init_distributed] cdb=None\n",
      "[2023-08-29 17:14:20,084] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "PID of this process = 2976659\n",
      "device: cuda:0\n",
      "Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'bf16': {'enabled': False}, 'fp16': {'enabled': True}, 'zero_optimization': {'stage': 2, 'contiguous_gradients': True, 'stage3_gather_16bit_weights_on_model_save': True, 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_prefetch_bucket_size': 10000000.0, 'stage3_param_persistence_threshold': 100000.0, 'reduce_bucket_size': 10000000.0, 'sub_group_size': 1000000000.0, 'offload_optimizer': {'device': 'none', 'nvme_path': '/scratch', 'pin_memory': True}, 'offload_param': {'device': 'none', 'nvme_path': '/scratch', 'buffer_size': 4000000000.0, 'pin_memory': True}}, 'aio': {'block_size': 26214400, 'queue_depth': 32, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'train_batch_size': 128, 'train_micro_batch_size_per_gpu': 128, 'wall_clock_breakdown': False, 'zero_allow_untested_optimizer': True}\n",
      "\n",
      "distributed = True num_devices = 1 local rank = 0 world size = 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import webdataset as wds\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "# tf32 data type is faster than standard float32\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# custom functions #\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5d2e32-6027-4a19-bef4-5ca068db35bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_rank = os.getenv('RANK')\n",
    "if local_rank is None: \n",
    "    local_rank = 0\n",
    "else:\n",
    "    local_rank = int(local_rank)\n",
    "print(\"LOCAL RANK \", local_rank)\n",
    "\n",
    "### Single-GPU config ###\n",
    "## Feel free to uncomment the below 4 lines and comment out all the multi-gpu config code to simplify things for single-gpu\n",
    "# from accelerate import Accelerator\n",
    "# num_devices = torch.cuda.device_count()\n",
    "# if num_devices==0: num_devices = 1\n",
    "# accelerator = Accelerator(split_batches=False)\n",
    "                          \n",
    "### Multi-GPU config ###\n",
    "from accelerate import Accelerator, DeepSpeedPlugin\n",
    "num_devices = torch.cuda.device_count()\n",
    "if num_devices==0: num_devices = 1\n",
    "if num_devices <= 1 and utils.is_interactive():\n",
    "    # can emulate a distributed environment for deepspeed to work in jupyter notebook\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = str(np.random.randint(10000)+9000)\n",
    "    os.environ[\"RANK\"] = \"0\"\n",
    "    os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "    os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "    os.environ[\"GLOBAL_BATCH_SIZE\"] = \"128\" # set this to your batch size!\n",
    "    batch_size = os.environ[\"GLOBAL_BATCH_SIZE\"]\n",
    "\n",
    "# alter the deepspeed config according to your global and local batch size\n",
    "if local_rank == 0:\n",
    "    with open('deepspeed_config_stage2.json', 'r') as file:\n",
    "        config = json.load(file)\n",
    "    config['train_batch_size'] = int(os.environ[\"GLOBAL_BATCH_SIZE\"])\n",
    "    config['train_micro_batch_size_per_gpu'] = int(os.environ[\"GLOBAL_BATCH_SIZE\"]) // num_devices\n",
    "    with open('deepspeed_config_stage2.json', 'w') as file:\n",
    "        json.dump(config, file)\n",
    "else:\n",
    "    # give some time for the local_rank=0 gpu to prep new deepspeed config file\n",
    "    time.sleep(10)\n",
    "deepspeed_plugin = DeepSpeedPlugin(\"deepspeed_config_stage2.json\")\n",
    "accelerator = Accelerator(split_batches=False, deepspeed_plugin=deepspeed_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b767ab6f-d4a9-47a5-b3bf-f56bf6760c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PID of this process =\",os.getpid())\n",
    "device = accelerator.device\n",
    "print(\"device:\",device)\n",
    "num_workers = num_devices\n",
    "print(accelerator.state)\n",
    "world_size = accelerator.state.num_processes\n",
    "distributed = not accelerator.state.distributed_type == 'NO'\n",
    "print(\"distributed =\",distributed, \"num_devices =\", num_devices, \"local rank =\", local_rank, \"world size =\", world_size)\n",
    "print = accelerator.print # only print if local_rank=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9018b82b-c054-4463-9527-4b0c2a75bda6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b61fec7-72a0-4b67-86da-1375f1d9fbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--data_path=/fsx/proj-fmri/shared/mindeyev2_dataset', '--model_name=test', '--subj=1', '--batch_size=128', '--n_samples_save=0', '--max_lr=3e-4', '--mixup_pct=.66', '--num_epochs=12', '--ckpt_interval=999', '--no-use_image_aug']\n"
     ]
    }
   ],
   "source": [
    "# if running this interactively, can specify jupyter_args here for argparser to use\n",
    "if utils.is_interactive():\n",
    "    # Example use\n",
    "    jupyter_args = f\"--data_path=/fsx/proj-fmri/shared/mindeyev2_dataset \\\n",
    "                    --model_name=test \\\n",
    "                    --subj=1 --batch_size={batch_size} --n_samples_save=0 \\\n",
    "                    --max_lr=3e-4 --mixup_pct=.66 --num_epochs=12 --ckpt_interval=999 --no-use_image_aug\"\n",
    "\n",
    "    jupyter_args = jupyter_args.split()\n",
    "    print(jupyter_args)\n",
    "    \n",
    "    from IPython.display import clear_output # function to clear print outputs in cell\n",
    "    %load_ext autoreload \n",
    "    # this allows you to change functions in models.py or utils.py and have this notebook automatically update with your revisions\n",
    "    %autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2028bdf0-2f41-46d9-b6e7-86b870dbf16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global batch_size 128\n",
      "batch_size 128\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Model Training Configuration\")\n",
    "parser.add_argument(\n",
    "    \"--model_name\", type=str, default=\"testing\",\n",
    "    help=\"name of model, used for ckpt saving and wandb logging (if enabled)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--data_path\", type=str, default=\"/fsx/proj-fmri/shared/natural-scenes-dataset\",\n",
    "    help=\"Path to where NSD data is stored / where to download it to\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--subj\",type=int, default=1, choices=[1,2,5,7],\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--batch_size\", type=int, default=32,\n",
    "    help=\"Batch size can be increased by 10x if only training v2c and not diffusion prior\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--wandb_log\",action=argparse.BooleanOptionalAction,default=False,\n",
    "    help=\"whether to log to wandb\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--resume_from_ckpt\",action=argparse.BooleanOptionalAction,default=False,\n",
    "    help=\"if not using wandb and want to resume from a ckpt\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--wandb_project\",type=str,default=\"stability\",\n",
    "    help=\"wandb project name\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--mixup_pct\",type=float,default=.33,\n",
    "    help=\"proportion of way through training when to switch from BiMixCo to SoftCLIP\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--use_image_aug\",action=argparse.BooleanOptionalAction,default=True,\n",
    "    help=\"whether to use image augmentation\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num_epochs\",type=int,default=240,\n",
    "    help=\"number of epochs of training\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--lr_scheduler_type\",type=str,default='cycle',choices=['cycle','linear'],\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--ckpt_saving\",action=argparse.BooleanOptionalAction,default=True,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--ckpt_interval\",type=int,default=5,\n",
    "    help=\"save backup ckpt and reconstruct every x epochs\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--seed\",type=int,default=42,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--max_lr\",type=float,default=3e-4,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n_samples_save\",type=int,default=0,choices=[0,1],\n",
    "    help=\"Number of reconstructions for monitoring progress, 0 will speed up training\",\n",
    ")\n",
    "\n",
    "if utils.is_interactive():\n",
    "    args = parser.parse_args(jupyter_args)\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "\n",
    "# create global variables without the args prefix\n",
    "for attribute_name in vars(args).keys():\n",
    "    globals()[attribute_name] = getattr(args, attribute_name)\n",
    "\n",
    "print(\"global batch_size\", batch_size)\n",
    "batch_size = int(batch_size / num_devices)\n",
    "print(\"batch_size\", batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60cd7f2c-37fd-426b-a0c6-633e51bc4c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outdir = os.path.abspath(f'../train_logs/{model_name}')\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir,exist_ok=True)\n",
    "if use_image_aug:\n",
    "    import kornia\n",
    "    from kornia.augmentation.container import AugmentationSequential\n",
    "    img_augment = AugmentationSequential(\n",
    "        kornia.augmentation.RandomResizedCrop((224,224), (0.6,1), p=0.3),\n",
    "        kornia.augmentation.Resize((224, 224)),\n",
    "        kornia.augmentation.RandomHorizontalFlip(p=0.3),\n",
    "        kornia.augmentation.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1, p=0.3),\n",
    "        kornia.augmentation.RandomGrayscale(p=0.3),\n",
    "        same_on_batch=False,\n",
    "        data_keys=[\"input\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d13c25-1369-4c49-81d4-83d713586096",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prep data, models, and dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c023f24-5233-4a15-a2f5-78487b3a8546",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81084834-035f-4465-ad59-59e6b806a2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/fsx/proj-fmri/shared/mindeyev2_dataset/wds/subj01/train/{0..36}.tar\n",
      "/fsx/proj-fmri/shared/mindeyev2_dataset/wds/subj01/test/0.tar\n"
     ]
    }
   ],
   "source": [
    "if subj==1:\n",
    "    num_train = 24958\n",
    "    num_test = 2770\n",
    "test_batch_size = num_test\n",
    "\n",
    "def my_split_by_node(urls): return urls\n",
    "    \n",
    "train_url = f\"{data_path}/wds/subj0{subj}/train/\" + \"{0..36}.tar\"\n",
    "print(train_url)\n",
    "\n",
    "train_data = wds.WebDataset(train_url,resampled=False,nodesplitter=my_split_by_node)\\\n",
    "                    .shuffle(750, initial=1500, rng=random.Random(42))\\\n",
    "                    .decode(\"torch\")\\\n",
    "                    .rename(behav=\"behav.npy\", past_behav=\"past_behav.npy\", future_behav=\"future_behav.npy\", olds_behav=\"olds_behav.npy\")\\\n",
    "                    .to_tuple(*[\"behav\", \"past_behav\", \"future_behav\", \"olds_behav\"])\n",
    "train_dl = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=False, drop_last=False, pin_memory=True)\n",
    "\n",
    "test_url = f\"{data_path}/wds/subj0{subj}/test/\" + \"0.tar\"\n",
    "print(test_url)\n",
    "\n",
    "test_data = wds.WebDataset(test_url,resampled=False,nodesplitter=my_split_by_node)\\\n",
    "                    .shuffle(750, initial=1500, rng=random.Random(42))\\\n",
    "                    .decode(\"torch\")\\\n",
    "                    .rename(behav=\"behav.npy\", past_behav=\"past_behav.npy\", future_behav=\"future_behav.npy\", olds_behav=\"olds_behav.npy\")\\\n",
    "                    .to_tuple(*[\"behav\", \"past_behav\", \"future_behav\", \"olds_behav\"])\n",
    "test_dl = torch.utils.data.DataLoader(test_data, batch_size=test_batch_size, shuffle=False, drop_last=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203b060a-2dd2-4c35-929b-c576be82eb52",
   "metadata": {},
   "source": [
    "### check dataloaders are working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7a9c68c-c3c9-4080-bd99-067c4486dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_indices = []\n",
    "# test_images = []\n",
    "# for test_i, (behav, past_behav, future_behav, old_behav) in enumerate(test_dl):\n",
    "#     test_indices = np.append(test_indices, behav[:,0,5].numpy())\n",
    "#     test_images = np.append(test_images, behav[:,0,0].numpy())\n",
    "# test_indices = test_indices.astype(np.int16)\n",
    "# print(test_i, (test_i+1) * test_batch_size, len(test_indices))\n",
    "# print(\"---\\n\")\n",
    "\n",
    "# train_indices = []\n",
    "# train_images = []\n",
    "# for train_i, (behav, past_behav, future_behav, old_behav) in enumerate(train_dl):\n",
    "#     train_indices = np.append(train_indices, behav[:,0,5].long().numpy())\n",
    "#     train_images = np.append(train_images, behav[:,0,0].numpy())\n",
    "# train_indices = train_indices.astype(np.int16)\n",
    "# print(train_i, (train_i+1) * batch_size, len(train_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fad12c-f9fb-4408-8fd4-9bca324ad634",
   "metadata": {},
   "source": [
    "## Load voxel betas, K-means clustering model, and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "039dd330-7339-4f88-8f00-45f95e47baa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj01 betas loaded into memory\n",
      "voxels torch.Size([27750, 15729])\n",
      "images torch.Size([73000, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# load betas\n",
    "f = h5py.File(f'{data_path}/betas_all_subj0{subj}.hdf5', 'r')\n",
    "voxels = f['betas'][:]\n",
    "print(f\"subj0{subj} betas loaded into memory\")\n",
    "voxels = torch.Tensor(voxels).to(\"cpu\").half()\n",
    "if subj==1:\n",
    "    voxels = torch.hstack((voxels, torch.zeros((len(voxels), 5))))\n",
    "print(\"voxels\", voxels.shape)\n",
    "num_voxels = voxels.shape[-1]\n",
    "\n",
    "# load orig images\n",
    "f = h5py.File(f'{data_path}/coco_images_224_float16.hdf5', 'r')\n",
    "images = f['images'][:]\n",
    "images = torch.Tensor(images).to(\"cpu\").half()\n",
    "print(\"images\", images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0420dc0-199e-4c1a-857d-b1747058b467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT-L/14 cuda:0\n"
     ]
    }
   ],
   "source": [
    "from models import Clipper\n",
    "eva02_model = Clipper(\"ViT-L/14\", device=torch.device(f\"cuda:{local_rank}\"), hidden_state=True, norm_embs=True)\n",
    "\n",
    "clip_seq_dim = 257\n",
    "clip_emb_dim = 768\n",
    "hidden_dim = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c44c271b-173f-472e-b059-a2eda0f4c4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MindEyeModule()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MindEyeModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MindEyeModule, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "        \n",
    "model = MindEyeModule()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "038a5d61-4769-40b9-a004-f4e7b5b38bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param counts:\n",
      "64,430,080 total\n",
      "64,430,080 trainable\n",
      "param counts:\n",
      "64,430,080 total\n",
      "64,430,080 trainable\n",
      "torch.Size([2, 15729]) torch.Size([2, 4096])\n"
     ]
    }
   ],
   "source": [
    "class RidgeRegression(torch.nn.Module):\n",
    "    # make sure to add weight_decay when initializing optimizer\n",
    "    def __init__(self, input_size, out_features): \n",
    "        super(RidgeRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_size, out_features)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "        \n",
    "model.ridge = RidgeRegression(voxels.shape[1], out_features=hidden_dim)\n",
    "utils.count_params(model.ridge)\n",
    "utils.count_params(model)\n",
    "\n",
    "b = torch.randn((2,voxels.shape[1]))\n",
    "print(b.shape, model.ridge(b).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "863fcb22-f588-480f-ad1c-14bcda9130ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param counts:\n",
      "883,162,112 total\n",
      "883,162,112 trainable\n",
      "param counts:\n",
      "947,592,192 total\n",
      "947,592,192 trainable\n",
      "torch.Size([2, 4096]) torch.Size([2, 257, 768])\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "class BrainNetwork(nn.Module):\n",
    "    def __init__(self, out_dim=768, in_dim=15724, clip_size=768, h=4096, n_blocks=4, norm_type='ln', act_first=False, use_projector=True, drop1=.5, drop2=.15):\n",
    "        super().__init__()\n",
    "        norm_func = partial(nn.BatchNorm1d, num_features=h) if norm_type == 'bn' else partial(nn.LayerNorm, normalized_shape=h)\n",
    "        act_fn = partial(nn.ReLU, inplace=True) if norm_type == 'bn' else nn.GELU\n",
    "        act_and_norm = (act_fn, norm_func) if act_first else (norm_func, act_fn)\n",
    "        self.mlp = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(h, h),\n",
    "                *[item() for item in act_and_norm],\n",
    "                nn.Dropout(drop2)\n",
    "            ) for _ in range(n_blocks)\n",
    "        ])\n",
    "        self.lin1 = nn.Linear(h, out_dim, bias=True)\n",
    "        self.n_blocks = n_blocks\n",
    "        self.clip_size = clip_size\n",
    "        self.use_projector = use_projector\n",
    "        if use_projector:\n",
    "            self.projector = nn.Sequential(\n",
    "                nn.LayerNorm(clip_size),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(clip_size, 2048),\n",
    "                nn.LayerNorm(2048),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(2048, 2048),\n",
    "                nn.LayerNorm(2048),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(2048, clip_size)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        for res_block in range(self.n_blocks):\n",
    "            x = self.mlp[res_block](x)\n",
    "            x += residual\n",
    "            residual = x\n",
    "        x = x.reshape(len(x), -1)\n",
    "        x = self.lin1(x)\n",
    "        if self.use_projector:\n",
    "            return self.projector(x.reshape(len(x), -1, self.clip_size))\n",
    "        return x\n",
    "\n",
    "model.backbone = BrainNetwork(in_dim=hidden_dim, clip_size=clip_emb_dim, out_dim=clip_seq_dim*clip_emb_dim, use_projector=True)\n",
    "utils.count_params(model.backbone)\n",
    "utils.count_params(model)\n",
    "\n",
    "b = torch.randn((2,hidden_dim))\n",
    "print(b.shape, model.backbone(b).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e14d0482-dc42-43b9-9ce1-953c32f2c9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with model preparations!\n"
     ]
    }
   ],
   "source": [
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "opt_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.ridge.named_parameters()], 'weight_decay': 1e-2},\n",
    "    {'params': [p for n, p in model.backbone.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 1e-2},\n",
    "    {'params': [p for n, p in model.backbone.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.AdamW(opt_grouped_parameters, lr=max_lr)\n",
    "\n",
    "if lr_scheduler_type == 'linear':\n",
    "    lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "        optimizer,\n",
    "        total_iters=int(num_epochs*(num_train*num_devices//batch_size)),\n",
    "        last_epoch=-1\n",
    "    )\n",
    "elif lr_scheduler_type == 'cycle':\n",
    "    total_steps=int(num_epochs*(num_train*num_devices//batch_size))\n",
    "    lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, \n",
    "        max_lr=max_lr,\n",
    "        total_steps=total_steps,\n",
    "        final_div_factor=1000,\n",
    "        last_epoch=-1, pct_start=2/num_epochs\n",
    "    )\n",
    "    \n",
    "def save_ckpt(tag):    \n",
    "    ckpt_path = outdir+f'/{tag}.pth'\n",
    "    print(f'saving {ckpt_path}',flush=True)\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    try:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': unwrapped_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'lr_scheduler': lr_scheduler.state_dict(),\n",
    "            'train_losses': losses,\n",
    "            'test_losses': test_losses,\n",
    "            'lrs': lrs,\n",
    "            }, ckpt_path)\n",
    "    except:\n",
    "        print(\"Couldn't save... moving on to prevent crashing.\")\n",
    "    del unwrapped_model\n",
    "        \n",
    "print(\"\\nDone with model preparations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983f458b-35b8-49f2-b6db-80296cece730",
   "metadata": {},
   "source": [
    "# Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a25a662-daa8-4de9-9233-8364800fcb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for wandb\n",
    "if local_rank==0 and wandb_log: # only use main process for wandb logging\n",
    "    import wandb\n",
    "    \n",
    "    wandb_project = 'stability'\n",
    "    wandb_run = model_name\n",
    "    wandb_notes = ''\n",
    "    \n",
    "    print(f\"wandb {wandb_project} run {wandb_run}\")\n",
    "    wandb.login(host='https://stability.wandb.io')#, relogin=True)\n",
    "    wandb_config = {\n",
    "      \"model_name\": model_name,\n",
    "      \"clip_variant\": clip_variant,\n",
    "      \"batch_size\": batch_size,\n",
    "      \"num_epochs\": num_epochs,\n",
    "      \"use_image_aug\": use_image_aug,\n",
    "      \"max_lr\": max_lr,\n",
    "      \"lr_scheduler_type\": lr_scheduler_type,\n",
    "      \"mixup_pct\": mixup_pct,\n",
    "      \"num_train\": num_train,\n",
    "      \"num_test\": num_test,\n",
    "      \"seed\": seed,\n",
    "      \"distributed\": distributed,\n",
    "      \"num_devices\": num_devices,\n",
    "      \"world_size\": world_size,\n",
    "    }\n",
    "    print(\"wandb_config:\\n\",wandb_config)\n",
    "    if True: # wandb_auto_resume\n",
    "        print(\"wandb_id:\",model_name)\n",
    "        wandb.init(\n",
    "            id = model_name,\n",
    "            project=wandb_project,\n",
    "            name=wandb_run,\n",
    "            config=wandb_config,\n",
    "            notes=wandb_notes,\n",
    "            resume=\"allow\",\n",
    "        )\n",
    "    else:\n",
    "        wandb.init(\n",
    "            project=wandb_project,\n",
    "            name=wandb_run,\n",
    "            config=wandb_config,\n",
    "            notes=wandb_notes,\n",
    "        )\n",
    "else:\n",
    "    wandb_log = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5690151-2131-4918-b750-e869cbd1a8a8",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12de6387-6e18-4e4b-b5ce-a847d625330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "losses, test_losses, lrs = [], [], []\n",
    "best_test_loss = 1e9\n",
    "soft_loss_temps = utils.cosine_anneal(0.004, 0.0075, num_epochs - int(mixup_pct * num_epochs))\n",
    "\n",
    "# Optionally resume from checkpoint #\n",
    "if resume_from_ckpt:\n",
    "    print(\"\\n---resuming from last.pth ckpt---\\n\")\n",
    "    try:\n",
    "        checkpoint = torch.load(outdir+'/last.pth', map_location='cpu')\n",
    "    except:\n",
    "        print('last.pth failed... trying last_backup.pth')\n",
    "        checkpoint = torch.load(outdir+'/last_backup.pth', map_location='cpu')\n",
    "    epoch = checkpoint['epoch']\n",
    "    print(\"Epoch\",epoch)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "    diffusion_prior.load_state_dict(checkpoint['model_state_dict'])\n",
    "    del checkpoint\n",
    "elif wandb_log:\n",
    "    if wandb.run.resumed:\n",
    "        print(\"\\n---resuming from last.pth ckpt---\\n\")\n",
    "        try:\n",
    "            checkpoint = torch.load(outdir+'/last.pth', map_location='cpu')\n",
    "        except:\n",
    "            print('last.pth failed... trying last_backup.pth')\n",
    "            checkpoint = torch.load(outdir+'/last_backup.pth', map_location='cpu')\n",
    "        epoch = checkpoint['epoch']\n",
    "        print(\"Epoch\",epoch)\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "        diffusion_prior.load_state_dict(checkpoint['model_state_dict'])\n",
    "        del checkpoint\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99f09f76-4481-4133-b09a-a22b10dbc0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-29 17:15:07,939] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown\n",
      "[2023-08-29 17:15:08,922] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2023-08-29 17:15:08,924] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2023-08-29 17:15:08,924] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2023-08-29 17:15:08,925] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW\n",
      "[2023-08-29 17:15:08,925] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>\n",
      "[2023-08-29 17:15:08,925] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer\n",
      "[2023-08-29 17:15:08,926] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 10000000\n",
      "[2023-08-29 17:15:08,926] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500,000,000\n",
      "[2023-08-29 17:15:08,926] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: False\n",
      "[2023-08-29 17:15:08,927] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False\n",
      "Rank: 0 partition count [1, 1, 1] and sizes[(64430080, False), (882922240, False), (239872, False)] \n",
      "[2023-08-29 17:15:11,101] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states\n",
      "[2023-08-29 17:15:11,102] [INFO] [utils.py:786:see_memory_usage] MA 7.31 GB         Max_MA 7.31 GB         CA 7.33 GB         Max_CA 7 GB \n",
      "[2023-08-29 17:15:11,103] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 81.7 GB, percent = 7.3%\n",
      "[2023-08-29 17:15:11,281] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states\n",
      "[2023-08-29 17:15:11,282] [INFO] [utils.py:786:see_memory_usage] MA 14.37 GB         Max_MA 24.47 GB         CA 24.99 GB         Max_CA 25 GB \n",
      "[2023-08-29 17:15:11,283] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 81.7 GB, percent = 7.3%\n",
      "[2023-08-29 17:15:11,283] [INFO] [stage_1_and_2.py:493:__init__] optimizer state initialized\n",
      "[2023-08-29 17:15:11,424] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2023-08-29 17:15:11,425] [INFO] [utils.py:786:see_memory_usage] MA 14.37 GB         Max_MA 14.37 GB         CA 24.99 GB         Max_CA 25 GB \n",
      "[2023-08-29 17:15:11,426] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 81.7 GB, percent = 7.3%\n",
      "[2023-08-29 17:15:11,427] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW\n",
      "[2023-08-29 17:15:11,427] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2023-08-29 17:15:11,428] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2023-08-29 17:15:11,428] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[1.200000000000002e-05, 1.200000000000002e-05, 1.200000000000002e-05], mom=[(0.95, 0.999), (0.95, 0.999), (0.95, 0.999)]\n",
      "[2023-08-29 17:15:11,428] [INFO] [config.py:960:print] DeepSpeedEngine configuration:\n",
      "[2023-08-29 17:15:11,429] [INFO] [config.py:964:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2023-08-29 17:15:11,429] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 26214400, 'queue_depth': 32, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2023-08-29 17:15:11,430] [INFO] [config.py:964:print]   amp_enabled .................. False\n",
      "[2023-08-29 17:15:11,430] [INFO] [config.py:964:print]   amp_params ................... False\n",
      "[2023-08-29 17:15:11,430] [INFO] [config.py:964:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2023-08-29 17:15:11,431] [INFO] [config.py:964:print]   bfloat16_enabled ............. False\n",
      "[2023-08-29 17:15:11,431] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2023-08-29 17:15:11,431] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True\n",
      "[2023-08-29 17:15:11,432] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False\n",
      "[2023-08-29 17:15:11,432] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fba30340430>\n",
      "[2023-08-29 17:15:11,432] [INFO] [config.py:964:print]   communication_data_type ...... None\n",
      "[2023-08-29 17:15:11,433] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2023-08-29 17:15:11,433] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False\n",
      "[2023-08-29 17:15:11,433] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False\n",
      "[2023-08-29 17:15:11,433] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2023-08-29 17:15:11,434] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False\n",
      "[2023-08-29 17:15:11,434] [INFO] [config.py:964:print]   dataloader_drop_last ......... False\n",
      "[2023-08-29 17:15:11,434] [INFO] [config.py:964:print]   disable_allgather ............ False\n",
      "[2023-08-29 17:15:11,434] [INFO] [config.py:964:print]   dump_state ................... False\n",
      "[2023-08-29 17:15:11,435] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... None\n",
      "[2023-08-29 17:15:11,435] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False\n",
      "[2023-08-29 17:15:11,435] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2023-08-29 17:15:11,436] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2023-08-29 17:15:11,436] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0\n",
      "[2023-08-29 17:15:11,436] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100\n",
      "[2023-08-29 17:15:11,436] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06\n",
      "[2023-08-29 17:15:11,437] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01\n",
      "[2023-08-29 17:15:11,437] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False\n",
      "[2023-08-29 17:15:11,437] [INFO] [config.py:964:print]   elasticity_enabled ........... False\n",
      "[2023-08-29 17:15:11,438] [INFO] [config.py:964:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2023-08-29 17:15:11,438] [INFO] [config.py:964:print]   fp16_auto_cast ............... False\n",
      "[2023-08-29 17:15:11,438] [INFO] [config.py:964:print]   fp16_enabled ................. True\n",
      "[2023-08-29 17:15:11,438] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False\n",
      "[2023-08-29 17:15:11,439] [INFO] [config.py:964:print]   global_rank .................. 0\n",
      "[2023-08-29 17:15:11,439] [INFO] [config.py:964:print]   grad_accum_dtype ............. None\n",
      "[2023-08-29 17:15:11,439] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1\n",
      "[2023-08-29 17:15:11,439] [INFO] [config.py:964:print]   gradient_clipping ............ 1.0\n",
      "[2023-08-29 17:15:11,440] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0\n",
      "[2023-08-29 17:15:11,440] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2023-08-29 17:15:11,440] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 65536\n",
      "[2023-08-29 17:15:11,441] [INFO] [config.py:964:print]   load_universal_checkpoint .... False\n",
      "[2023-08-29 17:15:11,441] [INFO] [config.py:964:print]   loss_scale ................... 0\n",
      "[2023-08-29 17:15:11,441] [INFO] [config.py:964:print]   memory_breakdown ............. False\n",
      "[2023-08-29 17:15:11,441] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False\n",
      "[2023-08-29 17:15:11,442] [INFO] [config.py:964:print]   mics_shard_size .............. -1\n",
      "[2023-08-29 17:15:11,442] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2023-08-29 17:15:11,442] [INFO] [config.py:964:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2023-08-29 17:15:11,443] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False\n",
      "[2023-08-29 17:15:11,443] [INFO] [config.py:964:print]   optimizer_name ............... None\n",
      "[2023-08-29 17:15:11,443] [INFO] [config.py:964:print]   optimizer_params ............. None\n",
      "[2023-08-29 17:15:11,443] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2023-08-29 17:15:11,444] [INFO] [config.py:964:print]   pld_enabled .................. False\n",
      "[2023-08-29 17:15:11,444] [INFO] [config.py:964:print]   pld_params ................... False\n",
      "[2023-08-29 17:15:11,444] [INFO] [config.py:964:print]   prescale_gradients ........... False\n",
      "[2023-08-29 17:15:11,445] [INFO] [config.py:964:print]   scheduler_name ............... None\n",
      "[2023-08-29 17:15:11,445] [INFO] [config.py:964:print]   scheduler_params ............. None\n",
      "[2023-08-29 17:15:11,445] [INFO] [config.py:964:print]   sparse_attention ............. None\n",
      "[2023-08-29 17:15:11,445] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False\n",
      "[2023-08-29 17:15:11,446] [INFO] [config.py:964:print]   steps_per_print .............. inf\n",
      "[2023-08-29 17:15:11,446] [INFO] [config.py:964:print]   train_batch_size ............. 128\n",
      "[2023-08-29 17:15:11,446] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  128\n",
      "[2023-08-29 17:15:11,446] [INFO] [config.py:964:print]   use_node_local_storage ....... False\n",
      "[2023-08-29 17:15:11,447] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False\n",
      "[2023-08-29 17:15:11,447] [INFO] [config.py:964:print]   world_size ................... 1\n",
      "[2023-08-29 17:15:11,447] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True\n",
      "[2023-08-29 17:15:11,448] [INFO] [config.py:964:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=10000000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=PosixPath('/scratch'), buffer_count=5, buffer_size=4000000000, max_in_cpu=1,000,000,000, pin_memory=True) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=PosixPath('/scratch'), buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=10000000 param_persistence_threshold=100000 model_persistence_threshold=sys.maxsize max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True\n",
      "[2023-08-29 17:15:11,448] [INFO] [config.py:964:print]   zero_enabled ................. True\n",
      "[2023-08-29 17:15:11,448] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2023-08-29 17:15:11,448] [INFO] [config.py:964:print]   zero_optimization_stage ...... 2\n",
      "[2023-08-29 17:15:11,449] [INFO] [config.py:950:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"stage3_gather_16bit_weights_on_model_save\": true, \n",
      "        \"stage3_max_live_parameters\": 1.000000e+09, \n",
      "        \"stage3_max_reuse_distance\": 1.000000e+09, \n",
      "        \"stage3_prefetch_bucket_size\": 1.000000e+07, \n",
      "        \"stage3_param_persistence_threshold\": 1.000000e+05, \n",
      "        \"reduce_bucket_size\": 1.000000e+07, \n",
      "        \"sub_group_size\": 1.000000e+09, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"none\", \n",
      "            \"nvme_path\": \"/scratch\", \n",
      "            \"pin_memory\": true\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"none\", \n",
      "            \"nvme_path\": \"/scratch\", \n",
      "            \"buffer_size\": 4.000000e+09, \n",
      "            \"pin_memory\": true\n",
      "        }\n",
      "    }, \n",
      "    \"aio\": {\n",
      "        \"block_size\": 2.621440e+07, \n",
      "        \"queue_depth\": 32, \n",
      "        \"thread_count\": 1, \n",
      "        \"single_submit\": false, \n",
      "        \"overlap_events\": true\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"gradient_clipping\": 1.0, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"train_batch_size\": 128, \n",
      "    \"train_micro_batch_size_per_gpu\": 128, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model, optimizer, train_dl, test_dl, lr_scheduler = accelerator.prepare(\n",
    "model, optimizer, train_dl, test_dl, lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a3368c-e6ce-49cc-b970-ee3dba12dfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test starting with epoch 0 / 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | 0/12 [00:00<?, ?it/s]/admin/home-paulscotti/miniconda3/envs/mindeye/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-29 17:15:15,320] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648\n",
      "[2023-08-29 17:15:15,784] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648, reducing to 1073741824\n",
      "[2023-08-29 17:15:16,211] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824, reducing to 536870912\n",
      "[2023-08-29 17:15:16,654] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912, reducing to 268435456\n",
      "[2023-08-29 17:15:17,081] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456, reducing to 134217728\n",
      "[2023-08-29 17:15:17,511] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728, reducing to 67108864\n",
      "[2023-08-29 17:15:17,953] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864, reducing to 33554432\n",
      "[2023-08-29 17:15:18,382] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432, reducing to 16777216\n",
      "[2023-08-29 17:15:18,810] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216, reducing to 8388608\n",
      "[2023-08-29 17:15:19,254] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304\n",
      "[2023-08-29 17:15:19,681] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152\n",
      "[2023-08-29 17:15:20,126] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2097152, reducing to 1048576\n",
      "[2023-08-29 17:15:20,554] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1048576, reducing to 524288\n",
      "[2023-08-29 17:15:20,997] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 524288, reducing to 262144\n",
      "[2023-08-29 17:15:21,438] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144, reducing to 131072\n",
      "[2023-08-29 17:15:21,867] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 131072, reducing to 65536\n",
      "[2023-08-29 17:15:22,307] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768\n",
      "[2023-08-29 17:16:59,865] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32768, reducing to 16384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | 0/12 [02:10<?, ?it/s, test/loss=1.87, test/num_steps=1, test/test_bwd_pct_correct=0.443, test/test_fwd_pct_correct=0.703, train/bwd_pct_correct=0.129, train/fwd_pct_correct=0.181, train/loss=3.58, train/lr=0.000138, train/num_steps=196]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████████████████████████████████████████████████████████████████████████████                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | 1/12 [02:10<23:56, 130.58s/it, test/loss=1.87, test/num_steps=1, test/test_bwd_pct_correct=0.443, test/test_fwd_pct_correct=0.703, train/bwd_pct_correct=0.129, train/fwd_pct_correct=0.181, train/loss=3.58, train/lr=0.000138, train/num_steps=196]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-29 17:19:09,142] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16384, reducing to 8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████████████████████████████████████████████████████████████████████████████                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | 1/12 [04:00<23:56, 130.58s/it, test/loss=0.917, test/num_steps=2, test/test_bwd_pct_correct=0.713, test/test_fwd_pct_correct=0.9, train/bwd_pct_correct=0.492, train/fwd_pct_correct=0.526, train/loss=1.39, train/lr=0.000299, train/num_steps=392]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | 2/12 [05:51<19:47, 118.79s/it, test/loss=0.591, test/num_steps=3, test/test_bwd_pct_correct=0.857, test/test_fwd_pct_correct=0.917, train/bwd_pct_correct=0.655, train/fwd_pct_correct=0.623, train/loss=0.795, train/lr=0.000294, train/num_steps=588]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | 3/12 [07:41<17:14, 114.96s/it, test/loss=0.432, test/num_steps=4, test/test_bwd_pct_correct=0.92, test/test_fwd_pct_correct=0.96, train/bwd_pct_correct=0.713, train/fwd_pct_correct=0.649, train/loss=0.551, train/lr=0.000273, train/num_steps=784]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | 4/12 [09:32<15:05, 113.24s/it, test/loss=0.454, test/num_steps=5, test/test_bwd_pct_correct=0.89, test/test_fwd_pct_correct=0.963, train/bwd_pct_correct=0.727, train/fwd_pct_correct=0.657, train/loss=0.488, train/lr=0.00024, train/num_steps=980]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | 5/12 [11:23<13:07, 112.45s/it, test/loss=0.44, test/num_steps=6, test/test_bwd_pct_correct=0.93, test/test_fwd_pct_correct=0.963, train/bwd_pct_correct=0.732, train/fwd_pct_correct=0.66, train/loss=0.457, train/lr=0.000198, train/num_steps=1176]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | 6/12 [13:13<11:10, 111.78s/it, test/loss=0.42, test/num_steps=7, test/test_bwd_pct_correct=0.95, test/test_fwd_pct_correct=0.977, train/bwd_pct_correct=0.731, train/fwd_pct_correct=0.655, train/loss=0.441, train/lr=0.000151, train/num_steps=1372]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                                                                                                                                                                                                                                                                                          | 7/12 [15:04<09:16, 111.37s/it, test/loss=0.386, test/num_steps=8, test/test_bwd_pct_correct=0.933, test/test_fwd_pct_correct=0.97, train/bwd_pct_correct=0.972, train/fwd_pct_correct=0.972, train/loss=0.051, train/lr=0.000104, train/num_steps=1568]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                                                                                                                                                                                                           | 8/12 [16:55<07:23, 110.96s/it, test/loss=0.302, test/num_steps=9, test/test_bwd_pct_correct=0.957, test/test_fwd_pct_correct=0.98, train/bwd_pct_correct=0.972, train/fwd_pct_correct=0.972, train/loss=0.0521, train/lr=6.2e-5, train/num_steps=1764]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                                                                                                                            | 9/12 [18:45<05:33, 111.12s/it, test/loss=0.237, test/num_steps=10, test/test_bwd_pct_correct=0.953, test/test_fwd_pct_correct=0.993, train/bwd_pct_correct=0.974, train/fwd_pct_correct=0.974, train/loss=0.0534, train/lr=2.85e-5, train/num_steps=1960]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                             | 10/12 [20:36<03:41, 110.88s/it, test/loss=0.244, test/num_steps=11, test/test_bwd_pct_correct=0.933, test/test_fwd_pct_correct=0.98, train/bwd_pct_correct=0.973, train/fwd_pct_correct=0.973, train/loss=0.0662, train/lr=7.13e-6, train/num_steps=2156]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                              | 11/12 [22:26<01:50, 110.69s/it, test/loss=0.212, test/num_steps=12, test/test_bwd_pct_correct=0.967, test/test_fwd_pct_correct=0.983, train/bwd_pct_correct=0.974, train/fwd_pct_correct=0.974, train/loss=0.0714, train/lr=1.22e-8, train/num_steps=2352]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [22:26<00:00, 112.21s/it, test/loss=0.212, test/num_steps=12, test/test_bwd_pct_correct=0.967, test/test_fwd_pct_correct=0.983, train/bwd_pct_correct=0.974, train/fwd_pct_correct=0.974, train/loss=0.0714, train/lr=1.22e-8, train/num_steps=2352]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===Finished!===\n",
      "\n",
      "saving /fsx/proj-fmri/paulscotti/MindEyeV2/train_logs/test/last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"{model_name} starting with epoch {epoch} / {num_epochs}\")\n",
    "progress_bar = tqdm(range(epoch,num_epochs), ncols=1200, disable=(local_rank!=0))\n",
    "test_image, test_voxel = None, None\n",
    "mse = nn.MSELoss()\n",
    "for epoch in progress_bar:\n",
    "    model.train()\n",
    "    \n",
    "    fwd_percent_correct = 0.\n",
    "    bwd_percent_correct = 0.\n",
    "    test_fwd_percent_correct = 0.\n",
    "    test_bwd_percent_correct = 0.\n",
    "\n",
    "    for train_i, (behav, past_behav, future_behav, old_behav) in enumerate(train_dl):\n",
    "        with torch.cuda.amp.autocast():\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            voxel = voxels[behav[:,0,5].cpu().long()].to(device)\n",
    "            image = images[behav[:,0,0].cpu().long()].to(device)\n",
    "            \n",
    "            if use_image_aug: image = img_augment(image)\n",
    "            \n",
    "            clip_target = eva02_model.embed_image(image.float())\n",
    "            assert not torch.any(torch.isnan(clip_target))\n",
    "\n",
    "            if epoch < int(mixup_pct * num_epochs):\n",
    "                voxel, perm, betas, select = utils.mixco(voxel)\n",
    "\n",
    "            voxel_ridge = model.ridge(voxel)\n",
    "            \n",
    "            clip_voxels = model.backbone(voxel_ridge)\n",
    "            \n",
    "            clip_voxels_norm = nn.functional.normalize(clip_voxels.flatten(1), dim=-1)\n",
    "            clip_target_norm = nn.functional.normalize(clip_target.flatten(1), dim=-1)\n",
    "\n",
    "            if epoch < int(mixup_pct * num_epochs):                \n",
    "                loss_clip = utils.mixco_nce(\n",
    "                    clip_voxels_norm,\n",
    "                    clip_target_norm,\n",
    "                    temp=.006, \n",
    "                    perm=perm, betas=betas, select=select)\n",
    "            else:\n",
    "                epoch_temp = soft_loss_temps[epoch-int(mixup_pct*num_epochs)]\n",
    "                loss_clip = utils.soft_clip_loss(\n",
    "                    clip_voxels_norm,\n",
    "                    clip_target_norm,\n",
    "                    temp=epoch_temp)\n",
    "                \n",
    "            loss = loss_clip\n",
    "            \n",
    "            utils.check_loss(loss)\n",
    "\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "    \n",
    "            losses.append(loss.item())\n",
    "            lrs.append(optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "            # forward and backward top 1 accuracy        \n",
    "            labels = torch.arange(len(clip_target_norm)).to(clip_voxels_norm.device) \n",
    "            fwd_percent_correct += utils.topk(utils.batchwise_cosine_similarity(clip_voxels_norm, clip_target_norm), labels, k=1)\n",
    "            bwd_percent_correct += utils.topk(utils.batchwise_cosine_similarity(clip_target_norm, clip_voxels_norm), labels, k=1)\n",
    "\n",
    "            if lr_scheduler_type is not None:\n",
    "                lr_scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    for test_i, (behav, past_behav, future_behav, old_behav) in enumerate(test_dl):\n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast():    \n",
    "                # all test samples should be loaded per batch such that test_i should never exceed 0\n",
    "                if len(behav) != num_test: print(\"!\",len(behav),num_test)\n",
    "                \n",
    "                ## Average same-image repeats ##\n",
    "                if test_image is None:\n",
    "                    voxel = voxels[behav[:,0,5].cpu().long()]\n",
    "                    image = behav[:,0,0].cpu().long()\n",
    "                    \n",
    "                    unique_image, sort_indices = torch.unique(image, return_inverse=True)\n",
    "                    for im in unique_image:\n",
    "                        locs = torch.where(im == image)[0]\n",
    "                        if test_image is None:\n",
    "                            test_image = images[im][None]\n",
    "                            test_voxel = torch.mean(voxel[locs],axis=0)[None]\n",
    "                        else:\n",
    "                            test_image = torch.vstack((test_image, images[im][None]))\n",
    "                            test_voxel = torch.vstack((test_voxel, torch.mean(voxel[locs],axis=0)[None]))\n",
    "    \n",
    "                # random sample of 300\n",
    "                random_indices = torch.randperm(len(test_voxel))[:300]\n",
    "                voxel = test_voxel[random_indices].to(device)\n",
    "                image = test_image[random_indices].to(device)\n",
    "                assert len(image) == 300\n",
    "        \n",
    "                clip_target = eva02_model.embed_image(image.float())\n",
    "                \n",
    "                voxel_ridge = model.ridge(voxel)\n",
    "                \n",
    "                clip_voxels = model.backbone(voxel_ridge)\n",
    "                \n",
    "                clip_voxels_norm = nn.functional.normalize(clip_voxels.flatten(1), dim=-1)\n",
    "                clip_target_norm = nn.functional.normalize(clip_target.flatten(1), dim=-1)\n",
    "        \n",
    "                loss_clip = utils.soft_clip_loss(\n",
    "                    clip_voxels_norm,\n",
    "                    clip_target_norm,\n",
    "                    temp=.006)\n",
    "                    \n",
    "                loss = loss_clip\n",
    "                \n",
    "                utils.check_loss(loss)\n",
    "        \n",
    "                test_losses.append(loss.item())\n",
    "        \n",
    "                # forward and backward top 1 accuracy        \n",
    "                labels = torch.arange(len(clip_target_norm)).to(clip_voxels_norm.device) \n",
    "                test_fwd_percent_correct += utils.topk(utils.batchwise_cosine_similarity(clip_voxels_norm, clip_target_norm), labels, k=1)\n",
    "                test_bwd_percent_correct += utils.topk(utils.batchwise_cosine_similarity(clip_target_norm, clip_voxels_norm), labels, k=1)\n",
    "\n",
    "    if local_rank==0:      \n",
    "        if utils.is_interactive():\n",
    "            # clear_output(wait=True)\n",
    "            print(\"---\")\n",
    "\n",
    "        assert (test_i+1) == 1\n",
    "        logs = {\"train/loss\": np.mean(losses[-(train_i+1):]),\n",
    "            \"test/loss\": np.mean(test_losses[-(test_i+1):]),\n",
    "            \"train/lr\": lrs[-1],\n",
    "            \"train/num_steps\": len(losses),\n",
    "            \"test/num_steps\": len(test_losses),\n",
    "            \"train/fwd_pct_correct\": fwd_percent_correct.item() / (train_i + 1),\n",
    "            \"train/bwd_pct_correct\": bwd_percent_correct.item() / (train_i + 1),\n",
    "            \"test/test_fwd_pct_correct\": test_fwd_percent_correct.item() / (test_i + 1),\n",
    "            \"test/test_bwd_pct_correct\": test_bwd_percent_correct.item() / (test_i + 1),\n",
    "            }\n",
    "        progress_bar.set_postfix(**logs)\n",
    "\n",
    "        # Save model checkpoint and reconstruct\n",
    "        if epoch % ckpt_interval == 0:\n",
    "            if not utils.is_interactive():\n",
    "                save_ckpt(f'last')\n",
    "                \n",
    "        if wandb_log: wandb.log(logs)\n",
    "\n",
    "    # wait for other GPUs to catch up if needed\n",
    "    accelerator.wait_for_everyone()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\n===Finished!===\\n\")\n",
    "if ckpt_saving:\n",
    "    save_ckpt(f'last')\n",
    "if not utils.is_interactive():\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5237bb-cfdc-44ed-b3fb-4fcfaffeb43b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "62aae01ef0cf7b6af841ab1c8ce59175c4332e693ab3d00bc32ceffb78a35376"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
