{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import math\n",
    "from einops import rearrange\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from statistics import *\n",
    "\n",
    "from torchmetrics.regression import PearsonCorrCoef\n",
    "\n",
    "os.chdir(\"/home/naxos2-raid25/ojeda040/local/ojeda040/MindEye_Imagery/src\")\n",
    "\n",
    "# SDXL unCLIP requires code from https://github.com/Stability-AI/generative-models/tree/main\n",
    "sys.path.append('generative_models/')\n",
    "import sgm\n",
    "from models import Clipper\n",
    "from generative_models.sgm.modules.encoders.modules import FrozenOpenCLIPImageEmbedder # bigG embedder\n",
    "\n",
    "# tf32 data type is faster than standard float32\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# custom functions #\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of voxels top 10rois: torch.Size([30000, 3665])\n",
      "Number of voxels top 11rois: torch.Size([30000, 5115])\n",
      "Number of voxels top 12rois: torch.Size([30000, 5615])\n",
      "Number of voxels top 13rois: torch.Size([30000, 6123])\n",
      "Number of voxels top 14rois: torch.Size([30000, 6802])\n",
      "Number of voxels top 15rois: torch.Size([30000, 6995])\n",
      "Number of voxels top 16rois: torch.Size([30000, 7468])\n",
      "Number of voxels top 17rois: torch.Size([30000, 7709])\n",
      "Number of voxels top 18rois: torch.Size([30000, 8315])\n",
      "Number of voxels top 19rois: torch.Size([30000, 14903])\n",
      "Number of voxels top 20rois: torch.Size([30000, 14968])\n",
      "Number of voxels top 21rois: torch.Size([30000, 14989])\n",
      "Number of voxels top 22rois: torch.Size([30000, 15003])\n",
      "Number of voxels top 23rois: torch.Size([30000, 20427])\n",
      "Number of voxels top 24rois: torch.Size([30000, 21123])\n",
      "Number of voxels top 25rois: torch.Size([30000, 21377])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(10, 26):\n",
    "    betas = load_subject_based_on_rank_order_rois(excluded_subject=1, data_type=torch.float16, top_n_rois=i)\n",
    "    print(\"Number of voxels top \" + str(i) + \" rois: \" + str(betas.shape))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
