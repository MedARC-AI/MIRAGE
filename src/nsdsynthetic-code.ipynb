{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/raid1/home/kneel027/miniconda3/envs/SS/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/export/raid1/home/kneel027/miniconda3/envs/SS/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/export/raid1/home/kneel027/miniconda3/envs/SS/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageEnhance\n",
    "import imageio.v3 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import pickle\n",
    "from scipy.io import loadmat\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [00:00<00:00, 278.38it/s]\n",
      "100%|██████████| 64/64 [00:00<00:00, 231.38it/s]\n",
      "100%|██████████| 64/64 [00:00<00:00, 227.90it/s]\n",
      "100%|██████████| 64/64 [00:00<00:00, 268.94it/s]\n",
      "100%|██████████| 64/64 [00:00<00:00, 271.82it/s]\n",
      "100%|██████████| 64/64 [00:00<00:00, 269.74it/s]\n",
      "100%|██████████| 64/64 [00:00<00:00, 220.36it/s]\n",
      "100%|██████████| 64/64 [00:00<00:00, 255.79it/s]\n",
      "100%|██████████| 64/64 [00:00<00:00, 273.67it/s]\n"
     ]
    }
   ],
   "source": [
    "file_path = 'nsddata_stimuli/stimuli/nsdsynthetic/nsdsynthetic_stimuli.hdf5'\n",
    "sf = h5py.File(file_path, 'r')\n",
    "sdataset = sf.get('imgBrick')\n",
    "stim_part1 = torch.zeros(220, 3, 714, 1360)\n",
    "for i in tqdm(range(220)):\n",
    "    im = transforms.ToPILImage()(sdataset[i])\n",
    "    im = transforms.ToTensor()(im)\n",
    "    stim_part1[i] = im\n",
    "torch.save(stim_part1, \"nsddata_stimuli/stimuli/nsdsynthetic/nsd_synthetic_stim_part1.pt\")\n",
    "\n",
    "for sub in range(1,9):\n",
    "    file_path = f'nsddata_stimuli/stimuli/nsdsynthetic/nsdsynthetic_colorstimuli_subj0{sub}.hdf5'\n",
    "    sf = h5py.File(file_path, 'r')\n",
    "    sdataset = sf.get('imgBrick')\n",
    "    stim_part2 = torch.zeros(64, 3, 714, 1360)\n",
    "    for i in tqdm(range(64)):\n",
    "        im = transforms.ToPILImage()(sdataset[i])\n",
    "        im = transforms.ToTensor()(im)\n",
    "        stim_part1[i] = im\n",
    "    torch.save(stim_part2, f\"nsddata_stimuli/stimuli/nsdsynthetic/nsd_synthetic_stim_part2_sub{sub}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore(x, mean=None, stddev=None, return_stats=False):\n",
    "    if mean is not None:\n",
    "        m = mean\n",
    "    else:\n",
    "        m = torch.mean(x, axis=0, keepdims=True)\n",
    "    if stddev is not None:\n",
    "        s = stddev\n",
    "    else:\n",
    "        s = torch.std(x, axis=0, keepdims=True)\n",
    "    if return_stats:\n",
    "        return (x - m)/(s+1e-6), m, s\n",
    "    else:\n",
    "        return (x - m)/(s+1e-6)\n",
    "    \n",
    "def create_whole_region_synthetic_unnormalized(subject = 1):\n",
    "\n",
    "    nsd_general = nib.load(f\"nsddata/ppdata/subj0{subject}/func1pt8mm/roi/nsdgeneral.nii.gz\").get_fdata()\n",
    "    nsd_general = np.nan_to_num(nsd_general)\n",
    "    nsd_general = np.where(nsd_general==1.0, True, False)\n",
    "\n",
    "    layer_size = np.sum(nsd_general == True)\n",
    "    os.makedirs(\"preprocessed_data/subject{}/\".format(subject), exist_ok=True)\n",
    "\n",
    "    whole_region = np.zeros((744, layer_size))\n",
    "\n",
    "    nsd_general_mask = np.nan_to_num(nsd_general)\n",
    "    nsd_mask = np.array(nsd_general_mask.flatten(), dtype=bool)\n",
    "    beta_file = f\"nsddata_betas/ppdata/subj0{subject}/func1pt8mm/nsdsyntheticbetas_fithrf_GLMdenoise_RR/betas_nsdsynthetic.nii.gz\"\n",
    "\n",
    "    imagery_betas = nib.load(beta_file).get_fdata()\n",
    "    imagery_betas = imagery_betas.transpose((3,0,1,2))\n",
    "    whole_region = torch.from_numpy(imagery_betas.reshape((len(imagery_betas), -1))[:,nsd_general.flatten()].astype(np.float32))\n",
    "\n",
    "    torch.save(whole_region, \"preprocessed_data/subject{}/nsd_synthetic_unnormalized.pt\".format(subject))\n",
    "    return whole_region\n",
    "\n",
    "def create_whole_region_synthetic_normalized(subject = 1):\n",
    "    unnormalized_file = f\"preprocessed_data/subject{subject}/nsd_synthetic_unnormalized\"\n",
    "    whole_region = torch.load(unnormalized_file + \".pt\")\n",
    "    whole_region = whole_region / 300.\n",
    "    whole_region_norm = torch.zeros_like(whole_region)\n",
    "\n",
    "    # Normalize the data using Z scoring method for each voxel\n",
    "    whole_region_norm = zscore(whole_region)\n",
    "\n",
    "    # Save the tensor of normalized data\n",
    "    torch.save(whole_region_norm, f\"preprocessed_data/subject{subject}/nsd_synthetic.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[198 231 196 152  53  18  23 180  25  34 221 240 202 141 108  52  14 249\n",
      "  24 203 149 149  12  23 112 264 264 189 136  90  27  23  87 226  86  21\n",
      " 216 216 255 224  43  77 272  28  22  59 155  33 283  27  95 195  26  26\n",
      " 244  21  55 148 110 131  23 273 197 260 126  22  22 150  20  20 140 251\n",
      " 215  17  16 127 127  69  83  68  68 132  67  37 165 186 186 104  10  10\n",
      "  21  72  91 261 230 230 217  27 190 256  58  41  41 234 278 278  16  28\n",
      " 225  81  80  14  26  29  29 182  28  28 239  20  35 138  98 211 199 147\n",
      " 238 271 271 169 209 129  92 268   3 161  44 222 227 245  66 269 210  99\n",
      " 252 262 100  25 277  17  13  25 107  50  22  15  89 276   6 124 167  60\n",
      "  60  17 153  15  15  26  84  11  15 177 270  25 103 103 113  18  82 172\n",
      " 130 171 178  40 170 170 219 118 188  46 114 114  20  63  63  54 102  19\n",
      "   2  32  19  19  42  42 258  28 119 119 105 109 237 101 259  76  76 156\n",
      " 183 248 248 163 243   9 181 173 254 139 175 160  13  71  13   1 218   4\n",
      " 116  70  79 151 274 213  39  85  22 120 235 275  96 128 142  48 214 214\n",
      "  51  74 246 263 200 143  16 123  17 162 162 133 193  78 192  64  64 159\n",
      "  24 144 111  20  19  21   7  13 122 157 157 236  61 137 117 179 207 121\n",
      " 284  30 176 166 187  57 281 265 232 247 145  18 204 204 208 242 206   8\n",
      " 220 220  36 266 135 194  88 253 250  49  97 201 184  47  16  16 158 279\n",
      " 125 229 229  26 185  14 233 233  75  62 241  56 282   5   5  38  65  19\n",
      "  24 115 146  18  18  73 280 257 257  93 228 168  31  45 106 134 164 191\n",
      "  14 205  94  27 174  24 212  15 267 223 223 154 261 230 230 217  27 190\n",
      " 256  58  41  41 234 278 278  16  28 225  81  80  14  26  29  29 182  28\n",
      "  28 239  20  35 138  98 211 199 147 238 271 271 169 209 129  92 268   3\n",
      " 161  44 222 227 245  66 269 210  99 252 262 100  25 277  17  13  25 107\n",
      "  50  22  15  89 276   6 124 167  60  60  17 153  15  15  26  84  11  15\n",
      " 177 270  25 103 103 113  18  82 172 130 171 178  40 170 170 198 231 196\n",
      " 152  53  18  23 180  25  34 221 240 202 141 108  52  14 249  24 203 149\n",
      " 149  12  23 112 264 264 189 136  90  27  23  87 226  86  21 216 216 255\n",
      " 224  43  77 272  28  22  59 155  33 283  27  95 195  26  26 244  21  55\n",
      " 148 110 131  23 273 197 260 126  22  22 150  20  20 140 251 215  17  16\n",
      " 127 127  69  83  68  68 132  67  37 165 186 186 104  10  10  21  72  91\n",
      " 157 157 236  61 137 117 179 207 121 284  30 176 166 187  57 281 265 232\n",
      " 247 145  18 204 204 208 242 206   8 220 220  36 266 135 194  88 253 250\n",
      "  49  97 201 184  47  16  16 158 279 125 229 229  26 185  14 233 233  75\n",
      "  62 241  56 282   5   5  38  65  19  24 115 146  18  18  73 280 257 257\n",
      "  93 228 168  31  45 106 134 164 191  14 205  94  27 174  24 212  15 267\n",
      " 223 223 154 219 118 188  46 114 114  20  63  63  54 102  19   2  32  19\n",
      "  19  42  42 258  28 119 119 105 109 237 101 259  76  76 156 183 248 248\n",
      " 163 243   9 181 173 254 139 175 160  13  71  13   1 218   4 116  70  79\n",
      " 151 274 213  39  85  22 120 235 275  96 128 142  48 214 214  51  74 246\n",
      " 263 200 143  16 123  17 162 162 133 193  78 192  64  64 159  24 144 111\n",
      "  20  19  21   7  13 122]\n",
      "[[[0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      "   0 0]\n",
      "  [0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0\n",
      "   0 0]\n",
      "  [0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      "   0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      "   1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      "   0 0]\n",
      "  [0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      "   1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      "   0 0]\n",
      "  [0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0\n",
      "   0 0]\n",
      "  [0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      "   0 0]\n",
      "  [0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      "   1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      "   0 0]\n",
      "  [0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      "   0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      "   1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      "   0 0]]]\n"
     ]
    }
   ],
   "source": [
    "stimuli_order = loadmat('nsddata/experiments/nsdsynthetic/nsdsynthetic_expdesign.mat')['masterordering'][0]\n",
    "print(stimuli_order)\n",
    "print(data['stimpattern'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_average(x, y, cond, nest=False):\n",
    "    idx, idx_count = np.unique(cond, return_counts=True)\n",
    "    idx_list = [np.array(cond)==i for i in np.sort(idx)]\n",
    "    if nest:\n",
    "        avg_x = torch.zeros((len(idx), idx_count.max(), x.shape[1]), dtype=torch.float32)\n",
    "    else:\n",
    "        avg_x = torch.zeros((len(idx), 1, x.shape[1]), dtype=torch.float32)\n",
    "    arranged_y = torch.zeros((len(idx)), y.shape[1], y.shape[2], y.shape[3])\n",
    "    for i, m in enumerate(idx_list):\n",
    "        if nest:\n",
    "            if np.sum(m) == idx_count.max():\n",
    "                avg_x[i] = x[m]\n",
    "            else:\n",
    "                avg_x[i,:np.sum(m)] = x[m]\n",
    "        else:\n",
    "            avg_x[i] = torch.mean(x[m], axis=0)\n",
    "        arranged_y[i] = y[m[0]]\n",
    "\n",
    "    return avg_x, y, len(idx_count)\n",
    "\n",
    "def load_nsd_synthetic(subject, average=False, nest=False):\n",
    "    y = torch.zeros((284, 3, 714, 1360))\n",
    "    y[:220] = torch.load(\"nsddata_stimuli/stimuli/nsdsynthetic/nsd_synthetic_stim_part1.pt\")\n",
    "    y[220:] = torch.load(f\"nsddata_stimuli/stimuli/nsdsynthetic/nsd_synthetic_stim_part2_sub{subject}.pt\")\n",
    "    \n",
    "    x = torch.load(\"preprocessed_data/subject{}/nsd_synthetic.pt\".format(subject)).requires_grad_(False).to(\"cpu\")\n",
    "    conditionals = loadmat('nsddata/experiments/nsdsynthetic/nsdsynthetic_expdesign.mat')['masterordering'][0].astype(int) - 1\n",
    "    \n",
    "    if average or nest:\n",
    "        x, y, sample_count = condition_average(x, y, conditionals, nest=nest)\n",
    "    else:\n",
    "        x = x.reshape((x.shape[0], 1, x.shape[1]))\n",
    "        y = y[conditionals]\n",
    "    print(x.shape, y.shape)\n",
    "    return x, y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/raid1/home/kneel027/Second-Sight/data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([744, 1, 15724]) torch.Size([744, 3, 714, 1360])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:02<00:20,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([744, 1, 14278]) torch.Size([744, 3, 714, 1360])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [00:05<00:17,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([744, 1, 15226]) torch.Size([744, 3, 714, 1360])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [00:08<00:14,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([744, 1, 13153]) torch.Size([744, 3, 714, 1360])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [00:11<00:11,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([744, 1, 13039]) torch.Size([744, 3, 714, 1360])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [00:14<00:08,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([744, 1, 17907]) torch.Size([744, 3, 714, 1360])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [00:17<00:05,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([744, 1, 12682]) torch.Size([744, 3, 714, 1360])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [00:20<00:02,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([744, 1, 14386]) torch.Size([744, 3, 714, 1360])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:24<00:00,  3.08s/it]\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "for subject in tqdm(range(1,9)):\n",
    "    create_whole_region_synthetic_unnormalized(subject)\n",
    "    create_whole_region_synthetic_normalized(subject)\n",
    "    x, y = load_nsd_synthetic(subject=subject, average=False, nest=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
