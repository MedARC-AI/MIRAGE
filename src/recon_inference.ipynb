{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f16c9d4c-66cb-4692-a61d-9aa86a8765d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/admin/home-mihirneal/miniconda3/envs/mindeye/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/admin/home-mihirneal/miniconda3/envs/mindeye/lib/python3.10/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCAL RANK  0\n",
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import math\n",
    "from einops import rearrange\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import webdataset as wds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from accelerate import Accelerator, DeepSpeedPlugin\n",
    "\n",
    "# SDXL unCLIP requires code from https://github.com/Stability-AI/generative-models/tree/main\n",
    "sys.path.append('generative_models/')\n",
    "import sgm\n",
    "from generative_models.sgm.modules.encoders.modules import FrozenOpenCLIPImageEmbedder, FrozenOpenCLIPEmbedder2\n",
    "from generative_models.sgm.models.diffusion import DiffusionEngine\n",
    "from generative_models.sgm.util import append_dims\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# tf32 data type is faster than standard float32\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# custom functions #\n",
    "import utils\n",
    "from models import *\n",
    "\n",
    "### Multi-GPU config ###\n",
    "local_rank = os.getenv('RANK')\n",
    "if local_rank is None: \n",
    "    local_rank = 0\n",
    "else:\n",
    "    local_rank = int(local_rank)\n",
    "print(\"LOCAL RANK \", local_rank)  \n",
    "\n",
    "accelerator = Accelerator(split_batches=False, mixed_precision=\"fp16\")\n",
    "device = accelerator.device\n",
    "print(\"device:\",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e52985b1-95ff-487b-8b2d-cc1ad1c190b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: control_MEV2\n",
      "--data_path=/weka/proj-fmri/shared/mindeyev2_dataset                     --model_name=control_MEV2 --subj=1                     --hidden_dim=1024 --n_blocks=4 --new_test\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# if running this interactively, can specify jupyter_args here for argparser to use\n",
    "if utils.is_interactive():\n",
    "    model_name = \"control_MEV2\"\n",
    "    print(\"model_name:\", model_name)\n",
    "\n",
    "    # global_batch_size and batch_size should already be defined in the above cells\n",
    "    # other variables can be specified in the following string:\n",
    "    jupyter_args = f\"--data_path=/weka/proj-fmri/shared/mindeyev2_dataset \\\n",
    "                    --model_name={model_name} --subj=1 \\\n",
    "                    --hidden_dim=1024 --n_blocks=4 --new_test\"\n",
    "    print(jupyter_args)\n",
    "    jupyter_args = jupyter_args.split()\n",
    "    \n",
    "    from IPython.display import clear_output # function to clear print outputs in cell\n",
    "    %load_ext autoreload \n",
    "    # this allows you to change functions in models.py or utils.py and have this notebook automatically update with your revisions\n",
    "    %autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49e5dae4-606d-4dc6-b420-df9e4c14737e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Model Training Configuration\")\n",
    "parser.add_argument(\n",
    "    \"--model_name\", type=str, default=\"testing\",\n",
    "    help=\"will load ckpt for model found in ../train_logs/model_name\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--data_path\", type=str, default=\"/weka/proj-fmri/shared/mindeyev2_dataset\",\n",
    "    help=\"Path to where NSD data is stored / where to download it to\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--subj\",type=int, default=1, choices=[1,2,3,4,5,6,7,8],\n",
    "    help=\"Validate on which subject?\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--blurry_recon\",action=argparse.BooleanOptionalAction,default=True,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n_blocks\",type=int,default=4,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--hidden_dim\",type=int,default=2048,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--new_test\",action=argparse.BooleanOptionalAction,default=True,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--seq_len\",type=int,default=1,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--seed\",type=int,default=42,\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--ckpt_path\",type=str,default=\"MindEyeV2/src/ablation_ckpt/control_MEV2\",\n",
    ")\n",
    "if utils.is_interactive():\n",
    "    args = parser.parse_args(jupyter_args)\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "\n",
    "# create global variables without the args prefix\n",
    "for attribute_name in vars(args).keys():\n",
    "    globals()[attribute_name] = getattr(args, attribute_name)\n",
    "    \n",
    "# seed all random functions\n",
    "utils.seed_everything(seed)\n",
    "\n",
    "# make output directory\n",
    "os.makedirs(\"evals\",exist_ok=True)\n",
    "os.makedirs(f\"evals/{model_name}\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64672583-9f00-46f5-8d4e-00e4c7068a1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_voxels for subj01: 15724\n",
      "/weka/proj-fmri/shared/mindeyev2_dataset/wds/subj01/new_test/0.tar\n",
      "Loaded test dl for subj1!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "voxels = {}\n",
    "# Load hdf5 data for betas\n",
    "f = h5py.File(f'{data_path}/betas_all_subj0{subj}_fp32_renorm.hdf5', 'r')\n",
    "betas = f['betas'][:]\n",
    "betas = torch.Tensor(betas).to(\"cpu\")\n",
    "num_voxels = betas[0].shape[-1]\n",
    "voxels[f'subj0{subj}'] = betas\n",
    "print(f\"num_voxels for subj0{subj}: {num_voxels}\")\n",
    "\n",
    "if not new_test: # using old test set from before full dataset released (used in original MindEye paper)\n",
    "    if subj==3:\n",
    "        num_test=2113\n",
    "    elif subj==4:\n",
    "        num_test=1985\n",
    "    elif subj==6:\n",
    "        num_test=2113\n",
    "    elif subj==8:\n",
    "        num_test=1985\n",
    "    else:\n",
    "        num_test=2770\n",
    "    test_url = f\"{data_path}/wds/subj0{subj}/test/\" + \"0.tar\"\n",
    "else: # using larger test set from after full dataset released\n",
    "    if subj==3:\n",
    "        num_test=2371\n",
    "    elif subj==4:\n",
    "        num_test=2188\n",
    "    elif subj==6:\n",
    "        num_test=2371\n",
    "    elif subj==8:\n",
    "        num_test=2188\n",
    "    else:\n",
    "        num_test=3000\n",
    "    test_url = f\"{data_path}/wds/subj0{subj}/new_test/\" + \"0.tar\"\n",
    "    \n",
    "print(test_url)\n",
    "def my_split_by_node(urls): return urls\n",
    "test_data = wds.WebDataset(test_url,resampled=False,nodesplitter=my_split_by_node)\\\n",
    "                    .decode(\"torch\")\\\n",
    "                    .rename(behav=\"behav.npy\", past_behav=\"past_behav.npy\", future_behav=\"future_behav.npy\", olds_behav=\"olds_behav.npy\")\\\n",
    "                    .to_tuple(*[\"behav\", \"past_behav\", \"future_behav\", \"olds_behav\"])\n",
    "test_dl = torch.utils.data.DataLoader(test_data, batch_size=num_test, shuffle=False, drop_last=True, pin_memory=True)\n",
    "print(f\"Loaded test dl for subj{subj}!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3cbeea8-e95b-48d9-9bc2-91af260c93d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3000 3000 1000\n"
     ]
    }
   ],
   "source": [
    "# Prep images but don't load them all to memory\n",
    "f = h5py.File(f'{data_path}/coco_images_224_float16.hdf5', 'r')\n",
    "images = f['images']\n",
    "\n",
    "# Prep test voxels and indices of test images\n",
    "test_images_idx = []\n",
    "test_voxels_idx = []\n",
    "for test_i, (behav, past_behav, future_behav, old_behav) in enumerate(test_dl):\n",
    "    test_voxels = voxels[f'subj0{subj}'][behav[:,0,5].cpu().long()]\n",
    "    test_voxels_idx = np.append(test_images_idx, behav[:,0,5].cpu().numpy())\n",
    "    test_images_idx = np.append(test_images_idx, behav[:,0,0].cpu().numpy())\n",
    "test_images_idx = test_images_idx.astype(int)\n",
    "test_voxels_idx = test_voxels_idx.astype(int)\n",
    "\n",
    "assert (test_i+1) * num_test == len(test_voxels) == len(test_images_idx)\n",
    "print(test_i, len(test_voxels), len(test_images_idx), len(np.unique(test_images_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3afc4858-b6a6-4a52-9303-b4a50ea5cc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param counts:\n",
      "83,653,863 total\n",
      "0 trainable\n",
      "param counts:\n",
      "16,102,400 total\n",
      "16,102,400 trainable\n",
      "param counts:\n",
      "458,885,116 total\n",
      "458,885,116 trainable\n",
      "param counts:\n",
      "474,987,516 total\n",
      "474,987,516 trainable\n",
      "param counts:\n",
      "259,865,216 total\n",
      "259,865,200 trainable\n",
      "param counts:\n",
      "734,852,732 total\n",
      "734,852,716 trainable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "734852716"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_img_embedder = FrozenOpenCLIPImageEmbedder(\n",
    "    arch=\"ViT-bigG-14\",\n",
    "    version=\"laion2b_s39b_b160k\",\n",
    "    output_tokens=True,\n",
    "    only_tokens=True,\n",
    ")\n",
    "clip_img_embedder.to(device)\n",
    "clip_seq_dim = 256\n",
    "clip_emb_dim = 1664\n",
    "\n",
    "if blurry_recon:\n",
    "    from diffusers import AutoencoderKL\n",
    "    autoenc = AutoencoderKL(\n",
    "        down_block_types=['DownEncoderBlock2D', 'DownEncoderBlock2D', 'DownEncoderBlock2D', 'DownEncoderBlock2D'],\n",
    "        up_block_types=['UpDecoderBlock2D', 'UpDecoderBlock2D', 'UpDecoderBlock2D', 'UpDecoderBlock2D'],\n",
    "        block_out_channels=[128, 256, 512, 512],\n",
    "        layers_per_block=2,\n",
    "        sample_size=256,\n",
    "    )\n",
    "    ckpt = torch.load('/weka/proj-fmri/shared/cache/sd_var_enc/sd_image_var_autoenc.pth')\n",
    "    autoenc.load_state_dict(ckpt)\n",
    "    autoenc.eval()\n",
    "    autoenc.requires_grad_(False)\n",
    "    autoenc.to(device)\n",
    "    utils.count_params(autoenc)\n",
    "    \n",
    "class MindEyeModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MindEyeModule, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "        \n",
    "model = MindEyeModule()\n",
    "\n",
    "class RidgeRegression(torch.nn.Module):\n",
    "    # make sure to add weight_decay when initializing optimizer\n",
    "    def __init__(self, input_sizes, out_features, seq_len): \n",
    "        super(RidgeRegression, self).__init__()\n",
    "        self.out_features = out_features\n",
    "        self.linears = torch.nn.ModuleList([\n",
    "                torch.nn.Linear(input_size, out_features) for input_size in input_sizes\n",
    "            ])\n",
    "    def forward(self, x, subj_idx):\n",
    "        out = torch.cat([self.linears[subj_idx](x[:,seq]).unsqueeze(1) for seq in range(seq_len)], dim=1)\n",
    "        return out\n",
    "        \n",
    "model.ridge = RidgeRegression([num_voxels], out_features=hidden_dim, seq_len=seq_len)\n",
    "\n",
    "from diffusers.models.vae import Decoder\n",
    "class BrainNetwork(nn.Module):\n",
    "    def __init__(self, h=4096, in_dim=15724, out_dim=768, seq_len=2, n_blocks=n_blocks, drop=.15, \n",
    "                 clip_size=768):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.h = h\n",
    "        self.clip_size = clip_size\n",
    "        \n",
    "        self.mixer_blocks1 = nn.ModuleList([\n",
    "            self.mixer_block1(h, drop) for _ in range(n_blocks)\n",
    "        ])\n",
    "        self.mixer_blocks2 = nn.ModuleList([\n",
    "            self.mixer_block2(seq_len, drop) for _ in range(n_blocks)\n",
    "        ])\n",
    "        \n",
    "        # Output linear layer\n",
    "        self.backbone_linear = nn.Linear(h * seq_len, out_dim, bias=True) \n",
    "        self.clip_proj = self.projector(clip_size, clip_size, h=clip_size)\n",
    "        \n",
    "        if blurry_recon:\n",
    "            self.blin1 = nn.Linear(h*seq_len,4*28*28,bias=True)\n",
    "            self.bdropout = nn.Dropout(.3)\n",
    "            self.bnorm = nn.GroupNorm(1, 64)\n",
    "            self.bupsampler = Decoder(\n",
    "                in_channels=64,\n",
    "                out_channels=4,\n",
    "                up_block_types=[\"UpDecoderBlock2D\",\"UpDecoderBlock2D\",\"UpDecoderBlock2D\"],\n",
    "                block_out_channels=[32, 64, 128],\n",
    "                layers_per_block=1,\n",
    "            )\n",
    "            self.b_maps_projector = nn.Sequential(\n",
    "                nn.Conv2d(64, 512, 1, bias=False),\n",
    "                nn.GroupNorm(1,512),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(512, 512, 1, bias=False),\n",
    "                nn.GroupNorm(1,512),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(512, 512, 1, bias=True),\n",
    "            )\n",
    "            \n",
    "    def projector(self, in_dim, out_dim, h=2048):\n",
    "        return nn.Sequential(\n",
    "            nn.LayerNorm(in_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(in_dim, h),\n",
    "            nn.LayerNorm(h),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(h, h),\n",
    "            nn.LayerNorm(h),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(h, out_dim)\n",
    "        )\n",
    "    \n",
    "    def mlp(self, in_dim, out_dim, drop):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_dim, out_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(out_dim, out_dim),\n",
    "        )\n",
    "    \n",
    "    def mixer_block1(self, h, drop):\n",
    "        return nn.Sequential(\n",
    "            nn.LayerNorm(h),\n",
    "            self.mlp(h, h, drop),  # Token mixing\n",
    "        )\n",
    "\n",
    "    def mixer_block2(self, seq_len, drop):\n",
    "        return nn.Sequential(\n",
    "            nn.LayerNorm(seq_len),\n",
    "            self.mlp(seq_len, seq_len, drop)  # Channel mixing\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make empty tensors\n",
    "        c,b,t = torch.Tensor([0.]), torch.Tensor([[0.],[0.]]), torch.Tensor([0.])\n",
    "        \n",
    "        # Mixer blocks\n",
    "        residual1 = x\n",
    "        residual2 = x.permute(0,2,1)\n",
    "        for block1, block2 in zip(self.mixer_blocks1,self.mixer_blocks2):\n",
    "            x = block1(x) + residual1\n",
    "            residual1 = x\n",
    "            x = x.permute(0,2,1)\n",
    "            \n",
    "            x = block2(x) + residual2\n",
    "            residual2 = x\n",
    "            x = x.permute(0,2,1)\n",
    "            \n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        backbone = self.backbone_linear(x).reshape(len(x), -1, self.clip_size)\n",
    "        c = self.clip_proj(backbone)\n",
    "\n",
    "        if blurry_recon:\n",
    "            b = self.blin1(x)\n",
    "            b = self.bdropout(b)\n",
    "            b = b.reshape(b.shape[0], -1, 7, 7).contiguous()\n",
    "            b = self.bnorm(b)\n",
    "            b_aux = self.b_maps_projector(b).flatten(2).permute(0,2,1)\n",
    "            b_aux = b_aux.view(len(b_aux), 49, 512)\n",
    "            b = (self.bupsampler(b), b_aux)\n",
    "        \n",
    "        return backbone, c, b\n",
    "\n",
    "model.backbone = BrainNetwork(h=hidden_dim, in_dim=hidden_dim, seq_len=seq_len, \n",
    "                          clip_size=clip_emb_dim, out_dim=clip_emb_dim*clip_seq_dim) \n",
    "utils.count_params(model.ridge)\n",
    "utils.count_params(model.backbone)\n",
    "utils.count_params(model)\n",
    "\n",
    "# setup diffusion prior network\n",
    "out_dim = clip_emb_dim\n",
    "depth = 6\n",
    "dim_head = 52\n",
    "heads = clip_emb_dim//52 # heads * dim_head = clip_emb_dim\n",
    "timesteps = 100\n",
    "\n",
    "prior_network = VersatileDiffusionPriorNetwork(\n",
    "        dim=out_dim,\n",
    "        depth=depth,\n",
    "        dim_head=dim_head,\n",
    "        heads=heads,\n",
    "        causal=False,\n",
    "        num_tokens = clip_seq_dim,\n",
    "        learned_query_mode=\"pos_emb\"\n",
    "    )\n",
    "\n",
    "model.diffusion_prior = BrainDiffusionPrior(\n",
    "    net=prior_network,\n",
    "    image_embed_dim=out_dim,\n",
    "    condition_on_text_encodings=False,\n",
    "    timesteps=timesteps,\n",
    "    cond_drop_prob=0.2,\n",
    "    image_embed_scale=None,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "utils.count_params(model.diffusion_prior)\n",
    "utils.count_params(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10412e31-ecc6-41ac-8a2d-854a19adc4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---loading /weka/proj-fmri/mihirneal/MindEyeV2/src/ablation_ckpt/control_MEV2 ckpt---\n",
      "\n",
      "Processing zero checkpoint '/weka/proj-fmri/mihirneal/MindEyeV2/src/ablation_ckpt/control_MEV2/pytorch_model'\n",
      "Detected checkpoint of type zero stage 2, world_size: 8\n",
      "Parsing checkpoint created by deepspeed==0.12.6\n",
      "Reconstructed Frozen fp32 state dict with 1 params 16 elements\n",
      "Reconstructed fp32 state dict with 230 params 734852716 elements\n",
      "ckpt loaded!\n"
     ]
    }
   ],
   "source": [
    "outdir = ckpt_path\n",
    "print(f\"\\n---loading {outdir} ckpt---\\n\")\n",
    "if True:\n",
    "#     checkpoint = torch.load(outdir+f'/{tag}.pth', map_location='cpu')\n",
    "#     try:\n",
    "#         model.module.load_state_dict(state_dict, strict=True)\n",
    "#     except:\n",
    "#         model.load_state_dict(state_dict, strict=True)\n",
    "#     del checkpoint\n",
    "# except: # probably ckpt is saved using deepspeed format\n",
    "    import deepspeed\n",
    "    state_dict = deepspeed.utils.zero_to_fp32.get_fp32_state_dict_from_zero_checkpoint(checkpoint_dir=outdir)\n",
    "    # try:\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    print(\"ckpt loaded!\")\n",
    "    # except:\n",
    "        # model.load_state_dict(state_dict, strict=False)\n",
    "        # print(\"ckpt loaded!\")\n",
    "    del state_dict\n",
    "# except:\n",
    "#     print(\"Can't load that shit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "295824db-ab3d-450c-90fb-f656e48994ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup text caption networks\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "from modeling_git import GitForCausalLMClipEmb\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/git-large-coco\")\n",
    "clip_text_model = GitForCausalLMClipEmb.from_pretrained(\"microsoft/git-large-coco\")\n",
    "clip_text_model.to(device) # if you get OOM running this script, you can switch this to cpu and lower minibatch_size to 4\n",
    "clip_text_model.eval().requires_grad_(False)\n",
    "clip_text_seq_dim = 257\n",
    "clip_text_emb_dim = 1024\n",
    "\n",
    "class CLIPConverter(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CLIPConverter, self).__init__()\n",
    "        self.linear1 = nn.Linear(clip_seq_dim, clip_text_seq_dim)\n",
    "        self.linear2 = nn.Linear(clip_emb_dim, clip_text_emb_dim)\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0,2,1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x.permute(0,2,1))\n",
    "        return x\n",
    "        \n",
    "clip_convert = CLIPConverter()\n",
    "state_dict = torch.load(\"/weka/proj-fmri/shared/mindeyev2_dataset/bigG_to_L_epoch8.pt\", map_location='cpu')['model_state_dict']\n",
    "clip_convert.load_state_dict(state_dict, strict=True)\n",
    "clip_convert.to(device) # if you get OOM running this script, you can switch this to cpu and lower minibatch_size to 4\n",
    "del state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f726f617-39f5-49e2-8d0c-d11d27d01c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sgm.modules.attention:SpatialTransformer: Found context dims [1664] of depth 1, which does not match the specified 'depth' of 2. Setting context_dim to [1664, 1664] now.\n",
      "WARNING:sgm.modules.attention:SpatialTransformer: Found context dims [1664] of depth 1, which does not match the specified 'depth' of 2. Setting context_dim to [1664, 1664] now.\n",
      "WARNING:sgm.modules.attention:SpatialTransformer: Found context dims [1664] of depth 1, which does not match the specified 'depth' of 10. Setting context_dim to [1664, 1664, 1664, 1664, 1664, 1664, 1664, 1664, 1664, 1664] now.\n",
      "WARNING:sgm.modules.attention:SpatialTransformer: Found context dims [1664] of depth 1, which does not match the specified 'depth' of 10. Setting context_dim to [1664, 1664, 1664, 1664, 1664, 1664, 1664, 1664, 1664, 1664] now.\n",
      "WARNING:sgm.modules.attention:SpatialTransformer: Found context dims [1664] of depth 1, which does not match the specified 'depth' of 10. Setting context_dim to [1664, 1664, 1664, 1664, 1664, 1664, 1664, 1664, 1664, 1664] now.\n",
      "WARNING:sgm.modules.attention:SpatialTransformer: Found context dims [1664] of depth 1, which does not match the specified 'depth' of 10. Setting context_dim to [1664, 1664, 1664, 1664, 1664, 1664, 1664, 1664, 1664, 1664] now.\n",
      "WARNING:sgm.modules.attention:SpatialTransformer: Found context dims [1664] of depth 1, which does not match the specified 'depth' of 10. Setting context_dim to [1664, 1664, 1664, 1664, 1664, 1664, 1664, 1664, 1664, 1664] now.\n",
      "WARNING:sgm.modules.attention:SpatialTransformer: Found context dims [1664] of depth 1, which does not match the specified 'depth' of 10. Setting context_dim to [1664, 1664, 1664, 1664, 1664, 1664, 1664, 1664, 1664, 1664] now.\n",
      "WARNING:sgm.modules.attention:SpatialTransformer: Found context dims [1664] of depth 1, which does not match the specified 'depth' of 2. Setting context_dim to [1664, 1664] now.\n",
      "WARNING:sgm.modules.attention:SpatialTransformer: Found context dims [1664] of depth 1, which does not match the specified 'depth' of 2. Setting context_dim to [1664, 1664] now.\n",
      "WARNING:sgm.modules.attention:SpatialTransformer: Found context dims [1664] of depth 1, which does not match the specified 'depth' of 2. Setting context_dim to [1664, 1664] now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized embedder #0: FrozenOpenCLIPImageEmbedder with 1909889025 params. Trainable: False\n",
      "Initialized embedder #1: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
      "Initialized embedder #2: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
      "vector_suffix torch.Size([1, 1024])\n"
     ]
    }
   ],
   "source": [
    "# prep unCLIP\n",
    "config = OmegaConf.load(\"generative_models/configs/unclip6.yaml\")\n",
    "config = OmegaConf.to_container(config, resolve=True)\n",
    "unclip_params = config[\"model\"][\"params\"]\n",
    "network_config = unclip_params[\"network_config\"]\n",
    "denoiser_config = unclip_params[\"denoiser_config\"]\n",
    "first_stage_config = unclip_params[\"first_stage_config\"]\n",
    "conditioner_config = unclip_params[\"conditioner_config\"]\n",
    "sampler_config = unclip_params[\"sampler_config\"]\n",
    "scale_factor = unclip_params[\"scale_factor\"]\n",
    "disable_first_stage_autocast = unclip_params[\"disable_first_stage_autocast\"]\n",
    "offset_noise_level = unclip_params[\"loss_fn_config\"][\"params\"][\"offset_noise_level\"]\n",
    "\n",
    "first_stage_config['target'] = 'sgm.models.autoencoder.AutoencoderKL'\n",
    "sampler_config['params']['num_steps'] = 38\n",
    "\n",
    "diffusion_engine = DiffusionEngine(network_config=network_config,\n",
    "                       denoiser_config=denoiser_config,\n",
    "                       first_stage_config=first_stage_config,\n",
    "                       conditioner_config=conditioner_config,\n",
    "                       sampler_config=sampler_config,\n",
    "                       scale_factor=scale_factor,\n",
    "                       disable_first_stage_autocast=disable_first_stage_autocast)\n",
    "# set to inference\n",
    "diffusion_engine.eval().requires_grad_(False)\n",
    "diffusion_engine.to(device)\n",
    "\n",
    "ckpt_path = '/weka/proj-fmri/shared/cache/sdxl_unclip/unclip6_epoch0_step110000.ckpt'\n",
    "ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "diffusion_engine.load_state_dict(ckpt['state_dict'])\n",
    "\n",
    "batch={\"jpg\": torch.randn(1,3,1,1).to(device), # jpg doesnt get used, it's just a placeholder\n",
    "      \"original_size_as_tuple\": torch.ones(1, 2).to(device) * 768,\n",
    "      \"crop_coords_top_left\": torch.zeros(1, 2).to(device)}\n",
    "out = diffusion_engine.conditioner(batch)\n",
    "vector_suffix = out[\"vector\"].to(device)\n",
    "print(\"vector_suffix\", vector_suffix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a706a3-d151-4643-bb34-7d08aa7361c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                          | 0/125 [00:00<?, ?it/s]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:   5%|████▋                                                                                     | 1/19 [00:00<00:04,  3.89it/s]\u001b[A\n",
      "sampling loop time step:  32%|████████████████████████████▍                                                             | 6/19 [00:00<00:00, 18.23it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 20.52it/s]\u001b[A\n",
      "sampling loop time step:  63%|████████████████████████████████████████████████████████▏                                | 12/19 [00:00<00:00, 21.92it/s]\u001b[A\n",
      "sampling loop time step:  79%|██████████████████████████████████████████████████████████████████████▎                  | 15/19 [00:00<00:00, 22.81it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 20.72it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a group of people sitting around a table.', 'a man standing in a room next to a table.', 'a surfer riding a wave.', 'a man on a surfboard in the water.', 'a building with a clock on it.', 'a plate of food with a bunch of vegetables on it.', 'a table with a piece of paper on it.', 'a group of people playing a game of soccer.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/admin/home-mihirneal/miniconda3/envs/mindeye/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/admin/home-mihirneal/miniconda3/envs/mindeye/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "  1%|▉                                                                                                               | 1/125 [00:48<1:40:20, 48.55s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.07it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.49it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.16it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.31it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.11it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a small dog is standing on a grass covered field.', 'a surfer riding a wave on a surfboard.', 'a plane is flying over the airport.', 'a surfer is riding a wave.', 'a bear in a field.', 'a woman sitting on a couch next to a woman.', 'a train is driving on the tracks.', 'a room with a couch, chair, and a table.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▊                                                                                                              | 2/125 [01:34<1:36:03, 46.86s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.07it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.49it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.17it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.32it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.11it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a man sitting down in a chair.', 'a large body of water.', 'a girl playing a game of tennis.', 'a bathroom with a toilet and sink.', 'a child is holding a baby.', 'a man standing next to a woman.', 'a building with a clock on it.', 'a group of people walking on a path.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▋                                                                                                             | 3/125 [02:19<1:34:05, 46.27s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.08it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.49it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.17it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.31it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.12it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a grassy field.', 'a man standing next to a bench.', 'a bunch of fruit sitting on a table.', 'a plane is flying in the air.', 'a bird is standing on a branch.', 'a girl sitting on a chair in front of a wall.', 'a banana with a few bananas on it.', 'a living room with a couch, chair, and television.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▌                                                                                                            | 4/125 [03:05<1:32:42, 45.97s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.07it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.48it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.17it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.32it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.11it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a room with a couch and a table', 'a room with a bed and a table', 'a plate of food with a fork.', 'a city with a lot of buildings.', 'a bus driving down a street next to a building.', 'a close up of a plate of food', 'a woman standing on a sidewalk next to a man.', 'a boat on a body of water.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████▍                                                                                                           | 5/125 [03:51<1:32:03, 46.03s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.06it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.49it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.17it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.32it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.11it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a man holding a tennis racket.', 'a large tree with a lot of leaves.', 'a large truck is parked on the side of the road.', 'a body of water with a boat in it.', 'a vase with flowers on it', 'a man standing in front of a building.', 'a plate of food with a fork.', 'a plane is parked on the runway.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████▍                                                                                                          | 6/125 [04:37<1:31:04, 45.92s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.08it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.50it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.18it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.32it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.13it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a street with a lot of cars on it', 'a young man is playing a game of tennis.', 'a bird sitting on a branch.', 'a person standing on a sidewalk.', 'a mountain with a mountain in the background.', 'a plane is flying in the sky.', 'a boat is sitting on the water.', 'a large building with a clock on it.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██████▎                                                                                                         | 7/125 [05:22<1:30:04, 45.80s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.09it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.50it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.18it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.32it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.11it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a motorcycle parked on the side of a road.', 'a train is driving on a track.', 'a plate of food with a piece of food on it.', 'a baseball player is standing in front of a batter.', 'a bicycle is parked on the sidewalk.', 'a bathroom with a toilet and sink.', 'a tennis player is on the court.', 'a plate of food with a fork']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|███████▏                                                                                                        | 8/125 [06:08<1:29:18, 45.80s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.12it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.50it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.18it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.32it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.13it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a snow covered ski slope.', 'a plate of food with a fork on it.', 'a man on a surfboard in the water.', 'a snowboarder is on a snowy hill.', 'a man standing next to a building.', 'a zebra grazing on grass.', 'a clock tower and a clock on a building.', 'a man on a surfboard in the ocean.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|████████                                                                                                        | 9/125 [06:53<1:28:15, 45.65s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 37.86it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.44it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.16it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.31it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.10it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a large animal in a field.', 'a plate of food', 'a beach with a bunch of people on it', 'a train is driving on a track.', 'a kite flying in the sky.', 'a man sitting down next to a table.', 'a table with a chair and a table with a lamp on it.', 'a person sitting on a couch.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████▉                                                                                                      | 10/125 [07:40<1:27:49, 45.82s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 37.99it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.49it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.18it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.33it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.11it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a glass vase with a plant in it.', 'a train is driving down the tracks.', 'a giraffe standing in a field.', 'a large parking lot.', 'a large field with a herd of cattle.', 'a surfer riding a wave.', 'a man standing on a tennis court.', 'a bird sitting on a ledge.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|█████████▊                                                                                                     | 11/125 [08:25<1:27:03, 45.82s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.11it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.51it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.18it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.32it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.13it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a man standing on a tennis court.', 'a surfer is riding a wave.', 'a herd of cattle grazing on a lush green field.', 'a living room with a couch, chair, and television.', 'a large area of grass.', 'a kitchen with a counter and a sink.', 'a clock tower with a tower in the background.', 'a plate of food with a spoon.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████████▋                                                                                                    | 12/125 [09:11<1:26:04, 45.71s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.13it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.52it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.20it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.34it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.14it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a surfer riding a wave on a surfboard.', 'a bunch of bananas on a table.', 'a black and white photo of a dog.', 'a room with a sink and a mirror.', 'a group of people sitting around a table.', 'a building with a clock on it.', 'a man standing next to a car.', 'a woman standing in a field.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████▌                                                                                                   | 13/125 [09:57<1:25:28, 45.79s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 37.34it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.28it/s]\u001b[A\n",
      "sampling loop time step:  63%|████████████████████████████████████████████████████████▏                                | 12/19 [00:00<00:00, 27.40it/s]\u001b[A\n",
      "sampling loop time step:  79%|██████████████████████████████████████████████████████████████████████▎                  | 15/19 [00:00<00:00, 26.38it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.06it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a snowboarder is snowboarding on a hill.', 'a bathroom with a toilet and sink.', 'a bird standing on a branch.', 'a boat on a body of water', 'a surfer on a surfboard in the ocean.', 'a truck parked next to a building.', 'a building with a clock on it', 'a skateboarder riding down a hill.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████████▍                                                                                                  | 14/125 [10:43<1:25:07, 46.01s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  21%|██████████████████▉                                                                       | 4/19 [00:00<00:00, 34.16it/s]\u001b[A\n",
      "sampling loop time step:  42%|█████████████████████████████████████▉                                                    | 8/19 [00:00<00:00, 27.84it/s]\u001b[A\n",
      "sampling loop time step:  58%|███████████████████████████████████████████████████▌                                     | 11/19 [00:00<00:00, 26.51it/s]\u001b[A\n",
      "sampling loop time step:  74%|█████████████████████████████████████████████████████████████████▌                       | 14/19 [00:00<00:00, 25.82it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 26.19it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a room with a view', 'a surfer riding a wave on a surfboard.', 'a bunch of food on a table', 'a plane is on the runway.', 'a man sitting on a bench next to a cell phone.', 'a man standing on top of a lush green field.', 'a horse riding on a field.', 'a plate of food with a fork.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████████▎                                                                                                 | 15/125 [11:29<1:24:26, 46.06s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:   5%|████▋                                                                                     | 1/19 [00:00<00:02,  8.86it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 25.06it/s]\u001b[A\n",
      "sampling loop time step:  42%|█████████████████████████████████████▉                                                    | 8/19 [00:00<00:00, 24.86it/s]\u001b[A\n",
      "sampling loop time step:  58%|███████████████████████████████████████████████████▌                                     | 11/19 [00:00<00:00, 24.77it/s]\u001b[A\n",
      "sampling loop time step:  74%|█████████████████████████████████████████████████████████████████▌                       | 14/19 [00:00<00:00, 24.72it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 24.07it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a plane is sitting on the runway.', 'a man standing next to a man.', 'a white bathroom with a sink and a mirror.', 'a bathroom with a toilet and a sink.', 'a baseball player is on the field.', 'a close up of a plate of food', 'a bathroom with a toilet and a sink.', 'a room with a view']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████████▏                                                                                                | 16/125 [12:16<1:23:41, 46.07s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.13it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.52it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.20it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.34it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.14it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a man standing next to a chair.', 'a room with a couch, chair, and a television.', 'a tree in a field', 'a surfer is riding a wave.', 'a group of people sitting around a table.', 'a man standing on a beach holding a surfboard.', 'a large area of dirt.', 'a man is wearing a suit and tie.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████████                                                                                                | 17/125 [13:01<1:22:50, 46.03s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.08it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.50it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.18it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.32it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.12it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a man sitting on a bench next to a bench.', 'a train parked on the side of a road.', 'a giraffe standing next to a tree.', 'a vase with flowers on it.', 'a plate of food with a fork.', 'a motorcycle parked on the side of a road.', 'a large bed with a white and blue striped blanket.', 'a group of people sitting down.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████████▉                                                                                               | 18/125 [13:47<1:21:55, 45.94s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.09it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.51it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.19it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.33it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.14it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a bathroom with a toilet and sink.', 'a bike is parked on the side of the road.', 'a close up of a person on a table', 'a grassy field with a tree in the background.', 'a plane is flying in the sky.', 'a bird is standing on a tree.', 'a plane is flying over the runway.', 'a surfer riding a wave on a surfboard.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████████▊                                                                                              | 19/125 [14:33<1:21:19, 46.04s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.07it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.49it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.18it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.32it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.12it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a plate of food with a fork and knife.', 'a fire hydrant is in the foreground.', 'a skier is skiing down a hill.', 'a large elephant standing in a field.', 'a group of people playing a game of soccer.', 'a computer desk with a laptop on it.', 'a man is holding a cell phone.', 'a small tree is in the foreground.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████████▊                                                                                             | 20/125 [15:19<1:20:26, 45.97s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.10it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.51it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.19it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.33it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.14it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a table with a chair', 'a woman is sitting on a bed.', 'a man standing on a tennis court.', 'a horse is standing on a field.', 'a bathroom with a toilet and a sink.', 'a bus driving down a street.', 'a large jetliner sitting on top of a cement.', 'a large group of people.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████████▋                                                                                            | 21/125 [16:05<1:19:48, 46.04s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.06it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.51it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.18it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.33it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.12it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a man on a beach with a surfboard.', 'a clock tower with a clock on it.', 'a tennis player is holding a racket.', 'a cow standing on a grass covered field.', 'a kitchen with a lot of counter space.', 'a surfer is riding a wave.', 'a bird is standing on a branch.', 'a plane is sitting on the runway.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████████▌                                                                                           | 22/125 [16:53<1:19:32, 46.33s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.08it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.49it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.18it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.32it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.13it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a plate of food with a fork.', 'a man standing in front of a wall.', 'a table with a bunch of items on it', 'a baseball player is standing on a field.', 'a bird is standing on a piece of land.', 'a train is driving on the tracks.', 'a white toilet', 'a skier is skiing down a hill.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████████▍                                                                                          | 23/125 [17:39<1:18:52, 46.40s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 37.88it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.45it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.14it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.29it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.09it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a man is holding a piece of paper.', 'a large building with a clock on it.', 'a man standing on a beach next to a surfboard.', 'a group of elephants standing around.', 'a man standing in front of a building.', 'a large elephant is standing in the dirt.', 'a street with a sidewalk and a sidewalk.', 'a tree in a field']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████████▎                                                                                         | 24/125 [18:26<1:18:16, 46.50s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.07it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.50it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.19it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.33it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.11it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a large building with a lot of windows.', 'a train is driving through a forest.', 'a large bear standing on a rock.', 'a group of people sitting around a table.', 'a white room with a toilet and a mirror.', 'a train is on the tracks.', 'a group of animals standing on top of a dirt field.', 'a train is driving on the tracks.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████████▏                                                                                        | 25/125 [19:12<1:17:24, 46.44s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.06it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.49it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.18it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.32it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.12it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a group of people standing around a bunch of people.', 'a snow skier is skiing on a mountain.', 'a group of people on a field with a horse.', 'a snow covered hill.', 'a boat on a body of water.', 'a plate of food with a bowl of food on it.', 'a street with a lot of traffic on it.', 'a building with a clock on it.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████████████                                                                                        | 26/125 [19:58<1:16:31, 46.37s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.12it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.53it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.21it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.34it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.14it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a clock on a building.', 'a man standing next to a table.', 'a clock tower with a tower in the background.', 'a plane is on the runway.', 'a train is driving down the tracks.', 'a white wall', 'a kitchen with a stove and a sink.', 'a plane is flying over the runway.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████████▉                                                                                       | 27/125 [20:46<1:16:17, 46.70s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.03it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.48it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.18it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.31it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.11it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a park with a lot of trees and a lot of trees', 'a surfer riding a wave on a surfboard.', 'a group of people eating at a table.', 'a plate of food with a knife and fork.', 'a man and a woman are standing together.', 'a clock tower and a building with a clock on it.', 'a zebra standing in a field.', 'a person holding a cell phone.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████████████▊                                                                                      | 28/125 [21:34<1:16:07, 47.09s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:   5%|████▋                                                                                     | 1/19 [00:00<00:03,  5.42it/s]\u001b[A\n",
      "sampling loop time step:  32%|████████████████████████████▍                                                             | 6/19 [00:00<00:00, 21.59it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 22.80it/s]\u001b[A\n",
      "sampling loop time step:  63%|████████████████████████████████████████████████████████▏                                | 12/19 [00:00<00:00, 23.47it/s]\u001b[A\n",
      "sampling loop time step:  79%|██████████████████████████████████████████████████████████████████████▎                  | 15/19 [00:00<00:00, 23.88it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 22.45it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a field with a tree and a fence', 'a large body of water.', 'a kite flying over a large field.', 'a man riding a bike down a street.', 'a zebra standing in a field.', 'a plate of food with a fork.', 'a train is driving down the tracks.', 'a train is parked on the tracks.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████████████▊                                                                                     | 29/125 [22:21<1:15:25, 47.14s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.01it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.48it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.18it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.32it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.12it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a bathroom with a toilet and a sink.', 'a man standing next to a building.', 'a truck parked on the side of a road.', 'a young man is holding a small child.', 'a snowboarder is skiing on a snowy mountain.', 'a large brown and white bear.', 'a bench in front of a tree.', 'a kite flying over a beach.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████████████▋                                                                                    | 30/125 [23:08<1:14:41, 47.17s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.09it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.50it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.18it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.32it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.12it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a white and black cat', 'a mountain with a mountain in the background.', 'a large field with a train and a large building.', 'a surfer riding a wave on a surfboard.', 'a man riding a surfboard on top of a body of water.', 'a plane is flying over the airport.', 'a bus driving down a street.', 'a plate of food with a fork.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████████▌                                                                                   | 31/125 [23:55<1:13:37, 46.99s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.08it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.49it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.17it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.32it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.12it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a tennis player is holding a racket.', 'a skateboarder is riding on a skateboard.', 'a cow standing on top of a lush green field.', 'a large concrete structure.', 'a snow covered ski slope.', 'a skateboarder is riding on a skateboard.', 'a man is wearing a suit and tie.', 'a white room with a mirror']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████████████▍                                                                                  | 32/125 [24:42<1:12:41, 46.90s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.07it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.49it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.18it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.31it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.11it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a man standing on a skateboard.', 'a man sitting on a bench.', 'a man standing next to a building.', 'a person on a skateboard on a sidewalk.', 'a cat sitting on a chair.', 'a table with a plate of food on it', 'a snowboarder is riding down a hill.', 'a train is driving down the tracks.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████████████████████████▎                                                                                 | 33/125 [25:29<1:12:03, 47.00s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.09it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.50it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.18it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.33it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.11it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a man standing on a beach next to a body of water.', 'a surfer on a surfboard in the ocean.', 'a woman sitting on a bench.', 'a skateboarder is standing on a skateboard.', 'a giraffe standing in the grass.', 'a vase with flowers and vases on it.', 'a person on a snow covered slope.', 'a bear in a field']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████████████████████████▏                                                                                | 34/125 [26:16<1:11:35, 47.21s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.07it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.50it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.18it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.32it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.13it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a street sign and a street sign.', 'a plate of food with a pizza on it.', 'a man sitting on a couch next to a chair.', 'a desk with a laptop on it.', 'a woman standing next to a man.', 'a horse is standing in the grass.', 'a stuffed animal sitting on top of a table.', 'a skateboarder is riding on a ramp.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████████████████                                                                                | 35/125 [27:05<1:11:18, 47.54s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.03it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.50it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.18it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.33it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.12it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a large bear standing on top of a lush green field.', 'a building with a clock on it.', 'a boat on a body of water.', 'a clock tower with a tower in the background.', 'a giraffe standing next to a tree.', 'a man standing next to a tree.', 'a room with a view', 'a man is wearing a suit and tie.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████████████▉                                                                               | 36/125 [27:53<1:10:43, 47.68s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  21%|██████████████████▉                                                                       | 4/19 [00:00<00:00, 34.03it/s]\u001b[A\n",
      "sampling loop time step:  42%|█████████████████████████████████████▉                                                    | 8/19 [00:00<00:00, 27.80it/s]\u001b[A\n",
      "sampling loop time step:  58%|███████████████████████████████████████████████████▌                                     | 11/19 [00:00<00:00, 26.49it/s]\u001b[A\n",
      "sampling loop time step:  74%|█████████████████████████████████████████████████████████████████▌                       | 14/19 [00:00<00:00, 25.80it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 26.16it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a train is driving on the tracks.', 'a living room with a couch, chair, and television.', 'a tennis player is on the court.', 'a zebra standing in a field.', 'a man sitting down.', 'a man and a woman are sitting on a bench.', 'a man walking down a street next to a building.', 'a man standing on a tennis court.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████████████▊                                                                              | 37/125 [28:41<1:10:08, 47.83s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.05it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.49it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.19it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.33it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.13it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a tennis player is playing on a court.', 'a building with a lot of windows', 'a bathroom with a toilet and a sink.', 'a man standing next to a building.', 'a bed with a pillow and a blanket', 'a large tree in a field.', 'a tennis player is on the court.', 'a room with a view']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████████████▋                                                                             | 38/125 [29:29<1:09:39, 48.04s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.05it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.49it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.18it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.31it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.12it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a bus driving down a street.', 'a man sitting on a bench next to a building.', 'a small animal is standing on a ground.', 'a long road with a train on it.', 'a large rock.', 'a bathroom with a sink and a mirror.', 'a plate of food with a knife.', 'a large white bear.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|██████████████████████████████████▋                                                                            | 39/125 [30:18<1:08:54, 48.07s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 37.54it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.34it/s]\u001b[A\n",
      "sampling loop time step:  63%|████████████████████████████████████████████████████████▏                                | 12/19 [00:00<00:00, 27.43it/s]\u001b[A\n",
      "sampling loop time step:  79%|██████████████████████████████████████████████████████████████████████▎                  | 15/19 [00:00<00:00, 26.41it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.09it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a large animal in a field.', 'a living room with a couch and television.', 'a herd of cattle grazing on a lush green hillside.', 'a large building with a lot of windows.', 'a man sitting on a couch next to a chair.', 'a herd of cattle grazing on a field.', 'a surfer riding a wave on a surfboard.', 'a table with a bunch of flowers on it']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████████████████▌                                                                           | 40/125 [31:06<1:08:24, 48.29s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.01it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.47it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.17it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.31it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.11it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a giraffe standing next to a tree.', 'a dog is sitting on a leash.', 'a kitchen with a microwave and a counter.', 'a bear in a field.', 'a cat sitting on a couch.', 'a group of people standing around a table.', 'a baseball player is standing on a field.', 'a bird is standing on a branch.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████████████▍                                                                          | 41/125 [31:56<1:08:08, 48.68s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:   5%|████▋                                                                                     | 1/19 [00:00<00:01,  9.21it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 25.40it/s]\u001b[A\n",
      "sampling loop time step:  42%|█████████████████████████████████████▉                                                    | 8/19 [00:00<00:00, 25.02it/s]\u001b[A\n",
      "sampling loop time step:  58%|███████████████████████████████████████████████████▌                                     | 11/19 [00:00<00:00, 24.87it/s]\u001b[A\n",
      "sampling loop time step:  74%|█████████████████████████████████████████████████████████████████▌                       | 14/19 [00:00<00:00, 24.78it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 24.17it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a man on a surfboard in the water.', 'a snowboarder is skiing down a hill.', 'a large building with a lot of windows.', 'a man riding a skateboard on top of a sidewalk.', 'a man riding a horse next to a fence.', 'a beach with a horse and a man on it', 'a small park with a bench and a tree.', 'a close up of a food']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████████████████▎                                                                         | 42/125 [32:44<1:07:12, 48.58s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.04it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.49it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.17it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.32it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.11it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a man on a beach with a surfboard.', 'a large white and brown horse.', 'a wall with a window', 'a skier is skiing on a snowy slope.', 'a group of people standing around each other.', 'a desk with a laptop and a monitor.', 'a skier is skiing on a snowy slope.', 'a man standing on top of a lush green field.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████████████████████████████▏                                                                        | 43/125 [33:33<1:06:21, 48.55s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.05it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.49it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.17it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.31it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.12it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a room with a toilet and a mirror.', 'a large body of water', 'a bird standing on a branch.', 'a tree in a field', 'a kite flying in the sky.', 'a close up of a person', 'a lone tree in a field.', 'a room with a couch, chair, and a table.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████████████████████                                                                        | 44/125 [34:21<1:05:32, 48.55s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.06it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.48it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.17it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.31it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.12it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a building with a lot of windows.', 'a snow covered mountain.', 'a restaurant with a lot of food.', 'a man standing on a tennis court.', 'bike parked on the street', 'a man laying down on a bed.', 'a close up of a person', 'a street with a sign and a street']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████████████▉                                                                       | 45/125 [35:09<1:04:12, 48.16s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.09it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.50it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.18it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.32it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.13it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a group of people standing around each other.', 'a plane is flying over the building.', 'a banana with a bunch of bananas on it.', 'a bathroom with a toilet and sink.', 'a man standing in front of a table.', 'a herd of elephants walking down a dirt road.', 'a man standing in front of a building.', 'a plane is flying over the runway.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████████████████▊                                                                      | 46/125 [35:57<1:03:22, 48.13s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.05it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.49it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.18it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.32it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.12it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a small animal is standing on a sidewalk.', 'a plate of food with a fork on it.', 'a plate of food with a bowl of food on it.', 'a large bear in a zoo.', 'a room with a view.', 'a man walking a dog', 'a skier is skiing down a hill.', 'a horse is standing on a horse.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████████████████▋                                                                     | 47/125 [36:44<1:02:13, 47.86s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.10it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.51it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.18it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.32it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.13it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a building with a clock on it.', 'a man standing on a beach next to a surfboard.', 'a man riding a surfboard on top of a wave.', 'a train is on the tracks.', 'a car driving down a street next to a parked car.', 'a man flying a kite in the air.', 'a street with a traffic sign and a street.', 'a large elephant standing in the grass.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████████████████▌                                                                    | 48/125 [37:31<1:01:17, 47.76s/it]\n",
      "sampling loop time step:   0%|                                                                                                  | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "sampling loop time step:  26%|███████████████████████▋                                                                  | 5/19 [00:00<00:00, 38.05it/s]\u001b[A\n",
      "sampling loop time step:  47%|██████████████████████████████████████████▋                                               | 9/19 [00:00<00:00, 29.48it/s]\u001b[A\n",
      "sampling loop time step:  68%|████████████████████████████████████████████████████████████▉                            | 13/19 [00:00<00:00, 27.16it/s]\u001b[A\n",
      "sampling loop time step:  84%|██████████████████████████████████████████████████████████████████████████▉              | 16/19 [00:00<00:00, 26.30it/s]\u001b[A\n",
      "sampling loop time step: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 27.10it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a surfer is riding a wave.', 'a kite is flying in the sky.', 'a bathroom with a toilet and a sink.', 'a man standing on top of a field.', 'a person sitting down.', 'a white wall with a mirror', 'a man riding a surfboard on top of a wave.', 'a herd of cattle grazing on a field.']\n"
     ]
    }
   ],
   "source": [
    "# get all reconstructions\n",
    "model.to(device)\n",
    "model.eval().requires_grad_(False)\n",
    "\n",
    "# all_images = None\n",
    "all_blurryrecons = None\n",
    "all_recons = None\n",
    "all_predcaptions = []\n",
    "all_clipvoxels = None\n",
    "\n",
    "minibatch_size = 8\n",
    "num_samples_per_image = 1\n",
    "plotting = False\n",
    "\n",
    "with torch.no_grad(), torch.cuda.amp.autocast(dtype=torch.float16):\n",
    "    for batch in tqdm(range(0,len(np.unique(test_images_idx)),minibatch_size)):\n",
    "        uniq_imgs = np.unique(test_images_idx)[batch:batch+minibatch_size]\n",
    "        voxel = None\n",
    "        for uniq_img in uniq_imgs:\n",
    "            locs = np.where(test_images_idx==uniq_img)[0]\n",
    "            if len(locs)==1:\n",
    "                locs = locs.repeat(3)\n",
    "            elif len(locs)==2:\n",
    "                locs = locs.repeat(2)[:3]\n",
    "            assert len(locs)==3\n",
    "            if voxel is None:\n",
    "                voxel = test_voxels[None,locs] # 1, num_image_repetitions, num_voxels\n",
    "            else:\n",
    "                voxel = torch.vstack((voxel, test_voxels[None,locs]))\n",
    "        voxel = voxel.to(device)\n",
    "        \n",
    "        for rep in range(3):\n",
    "            voxel_ridge = model.ridge(voxel[:,[rep]],0) # 0th index of subj_list\n",
    "            backbone0, clip_voxels0, blurry_image_enc0 = model.backbone(voxel_ridge)\n",
    "            if rep==0:\n",
    "                clip_voxels = clip_voxels0\n",
    "                backbone = backbone0\n",
    "                blurry_image_enc = blurry_image_enc0[0]\n",
    "            else:\n",
    "                clip_voxels += clip_voxels0\n",
    "                backbone += backbone0\n",
    "                blurry_image_enc += blurry_image_enc0[0]\n",
    "        clip_voxels /= 3\n",
    "        backbone /= 3\n",
    "        blurry_image_enc /= 3\n",
    "                \n",
    "        # Save retrieval submodule outputs\n",
    "        if all_clipvoxels is None:\n",
    "            all_clipvoxels = clip_voxels\n",
    "        else:\n",
    "            all_clipvoxels = torch.vstack((all_clipvoxels, clip_voxels))\n",
    "        \n",
    "        # Feed voxels through OpenCLIP-bigG diffusion prior\n",
    "        prior_out = model.diffusion_prior.p_sample_loop(backbone.shape, \n",
    "                        text_cond = dict(text_embed = backbone), \n",
    "                        cond_scale = 1., timesteps = 20)\n",
    "        \n",
    "        pred_caption_emb = clip_convert(prior_out)\n",
    "        generated_ids = clip_text_model.generate(pixel_values=pred_caption_emb, max_length=20)\n",
    "        generated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        all_predcaptions = np.hstack((all_predcaptions, generated_caption))\n",
    "        print(generated_caption)\n",
    "        \n",
    "        # Feed diffusion prior outputs through unCLIP\n",
    "        for i in range(len(voxel)):\n",
    "            samples = utils.unclip_recon(prior_out[[i]],\n",
    "                             diffusion_engine,\n",
    "                             vector_suffix,\n",
    "                             num_samples=num_samples_per_image)\n",
    "            if all_recons is None:\n",
    "                all_recons = samples.cpu()\n",
    "            else:\n",
    "                all_recons = torch.vstack((all_recons, samples.cpu()))\n",
    "            if plotting:\n",
    "                for s in range(num_samples_per_image):\n",
    "                    plt.figure(figsize=(2,2))\n",
    "                    plt.imshow(transforms.ToPILImage()(samples[s]))\n",
    "                    plt.axis('off')\n",
    "                    plt.show()\n",
    "\n",
    "        if blurry_recon:\n",
    "            blurred_image = (autoenc.decode(blurry_image_enc/0.18215).sample/ 2 + 0.5).clamp(0,1)\n",
    "            \n",
    "            for i in range(len(voxel)):\n",
    "                im = torch.Tensor(blurred_image[i])\n",
    "                if all_blurryrecons is None:\n",
    "                    all_blurryrecons = im[None].cpu()\n",
    "                else:\n",
    "                    all_blurryrecons = torch.vstack((all_blurryrecons, im[None].cpu()))\n",
    "                if plotting:\n",
    "                    plt.figure(figsize=(2,2))\n",
    "                    plt.imshow(transforms.ToPILImage()(im))\n",
    "                    plt.axis('off')\n",
    "                    plt.show()\n",
    "\n",
    "        if plotting: \n",
    "            print(model_name)\n",
    "            err # dont actually want to run the whole thing with plotting=True\n",
    "\n",
    "# resize outputs before saving\n",
    "imsize = 256\n",
    "all_recons = transforms.Resize((imsize,imsize))(all_recons).float()\n",
    "if blurry_recon: \n",
    "    all_blurryrecons = transforms.Resize((imsize,imsize))(all_blurryrecons).float()\n",
    "        \n",
    "# saving\n",
    "print(all_recons.shape)\n",
    "# torch.save(all_images,\"evals/all_images.pt\")\n",
    "if blurry_recon:\n",
    "    torch.save(all_blurryrecons,f\"evals/{model_name}/{model_name}_all_blurryrecons.pt\")\n",
    "torch.save(all_recons,f\"evals/{model_name}/{model_name}_all_recons.pt\")\n",
    "torch.save(all_predcaptions,f\"evals/{model_name}/{model_name}_all_predcaptions.pt\")\n",
    "torch.save(all_clipvoxels,f\"evals/{model_name}/{model_name}_all_clipvoxels.pt\")\n",
    "print(f\"saved {model_name} outputs!\")\n",
    "\n",
    "if not utils.is_interactive():\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914c4ee2-3fcd-47ae-934d-96dbf12fbcd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
