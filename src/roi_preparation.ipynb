{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from PIL import Image\n",
    "import nibabel as nib\n",
    "os.chdir(\"/home/naxos2-raid25/ojeda040/local/ojeda040/MindEye_Imagery/src\")\n",
    "\n",
    "from utils import *\n",
    "# # from autoencoder import AutoEncoder\n",
    "# from gnet8_encoder import GNet8_Encoder\n",
    "# from matplotlib.lines import Line2D\n",
    "# import matplotlib as mpl\n",
    "# import math\n",
    "# import matplotlib.image as mpimg\n",
    "# import random\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['early', 'midventral', 'midlateral', 'midparietal', 'ventral', 'lateral', 'parietal', 'nsd_general']) (array([False,  True]), array([230904,   7604]))\n"
     ]
    }
   ],
   "source": [
    "def get_kastner_rois(subject, data_path):\n",
    "    kastner_labels = f\"{data_path}/nsddata/freesurfer/subj0{subject}/label/Kastner2015.mgz.ctab\"\n",
    "    brainmask_inflated = nib.load(f\"{data_path}/nsddata/ppdata/subj0{subject}/func1pt8mm/roi/brainmask_inflated_1.0.nii\").get_fdata()\n",
    "    brainmask_inflated = np.nan_to_num(brainmask_inflated)\n",
    "    brainmask_inflated = np.where(brainmask_inflated==1.0, True, False)\n",
    "    kastner_mask = nib.load(f\"{data_path}/nsddata/ppdata/subj0{subject}/func1pt8mm/roi/Kastner2015.nii.gz\").get_fdata()\n",
    "    kastner_mask = kastner_mask[brainmask_inflated]\n",
    "    with open(kastner_labels, 'r') as file:\n",
    "        labels = file.read().splitlines()\n",
    "    kastner_mask_labeled = {}\n",
    "    for label in labels[1:]:\n",
    "        label = label.split(\" \")\n",
    "        kastner_mask_labeled[label[1].strip()] = np.where(kastner_mask==int(label[0]), True, False)\n",
    "    kastner_mask_labeled[\"V1\"] = np.logical_or(kastner_mask_labeled[\"V1v\"], kastner_mask_labeled[\"V1d\"])\n",
    "    kastner_mask_labeled[\"V2\"] = np.logical_or(kastner_mask_labeled[\"V2v\"], kastner_mask_labeled[\"V2d\"])\n",
    "    kastner_mask_labeled[\"V3\"] = np.logical_or(kastner_mask_labeled[\"V3v\"], kastner_mask_labeled[\"V3d\"])\n",
    "    del kastner_mask_labeled[\"V1v\"]\n",
    "    del kastner_mask_labeled[\"V1d\"]\n",
    "    del kastner_mask_labeled[\"V2v\"]\n",
    "    del kastner_mask_labeled[\"V2d\"]\n",
    "    del kastner_mask_labeled[\"V3v\"]\n",
    "    del kastner_mask_labeled[\"V3d\"]\n",
    "    nsd_general = nib.load(f\"{data_path}/nsddata/ppdata/subj0{subject}/func1pt8mm/roi/nsdgeneral.nii.gz\").get_fdata()\n",
    "    nsd_general = np.nan_to_num(nsd_general)\n",
    "    nsd_general = nsd_general[brainmask_inflated]\n",
    "    nsd_general = np.where(nsd_general==1.0, True, False)\n",
    "    kastner_mask_labeled['nsd_general'] = nsd_general\n",
    "    return kastner_mask_labeled\n",
    "\n",
    "def get_hcp_mmp1_rois(subject, data_path):\n",
    "    mmp1_labels = f\"{data_path}/nsddata/freesurfer/subj0{subject}/label/HCP_MMP1.mgz.ctab\"\n",
    "    brainmask_inflated = nib.load(f\"{data_path}/nsddata/ppdata/subj0{subject}/func1pt8mm/roi/brainmask_inflated_1.0.nii\").get_fdata()\n",
    "    brainmask_inflated = np.nan_to_num(brainmask_inflated)\n",
    "    brainmask_inflated = np.where(brainmask_inflated==1.0, True, False)\n",
    "    mmp1_mask = nib.load(f\"{data_path}/nsddata/ppdata/subj0{subject}/func1pt8mm/roi/HCP_MMP1.nii.gz\").get_fdata()\n",
    "    mmp1_mask = mmp1_mask[brainmask_inflated]\n",
    "    with open(mmp1_labels, 'r') as file:\n",
    "        labels = file.read().splitlines()\n",
    "    mmp1_mask_labeled = {}\n",
    "    for label in labels[1:]:\n",
    "        label = label.split(\" \")\n",
    "        mmp1_mask_labeled[label[1].strip()] = np.where(mmp1_mask==int(label[0]), True, False)\n",
    "    nsd_general = nib.load(f\"{data_path}/nsddata/ppdata/subj0{subject}/func1pt8mm/roi/nsdgeneral.nii.gz\").get_fdata()\n",
    "    nsd_general = np.nan_to_num(nsd_general)\n",
    "    nsd_general = nsd_general[brainmask_inflated]\n",
    "    nsd_general = np.where(nsd_general==1.0, True, False)\n",
    "    mmp1_mask_labeled['nsd_general'] = nsd_general\n",
    "    return mmp1_mask_labeled\n",
    "\n",
    "def get_thalamus_rois(subject, data_path):\n",
    "    thalamus_labels = f\"{data_path}/nsddata/templates/thalamus.ctab\"\n",
    "    brainmask_inflated = nib.load(f\"{data_path}/nsddata/ppdata/subj0{subject}/func1pt8mm/roi/brainmask_inflated_1.0.nii\").get_fdata()\n",
    "    brainmask_inflated = np.nan_to_num(brainmask_inflated)\n",
    "    brainmask_inflated = np.where(brainmask_inflated==1.0, True, False)\n",
    "    thalamus_mask = nib.load(f\"data/nsddata/ppdata/subj0{subject}/func1pt8mm/roi/thalamus.nii.gz\").get_fdata()\n",
    "    thalamus_mask = thalamus_mask[brainmask_inflated]\n",
    "    with open(thalamus_labels, 'r') as file:\n",
    "        labels = file.read().splitlines()\n",
    "    thalamus_mask_labeled = {}\n",
    "    for label in labels[1:]:\n",
    "        label = label.split(\" \")\n",
    "        thalamus_mask_labeled[label[1].strip()] = np.where(thalamus_mask==int(label[0]), True, False)\n",
    "    return thalamus_mask_labeled\n",
    "\n",
    "def get_mtl_rois(subject, data_path):\n",
    "    mtl_labels = f\"{data_path}/nsddata/templates/MTL.ctab\"\n",
    "    brainmask_inflated = nib.load(f\"{data_path}/nsddata/ppdata/subj0{subject}/func1pt8mm/roi/brainmask_inflated_1.0.nii\").get_fdata()\n",
    "    brainmask_inflated = np.nan_to_num(brainmask_inflated)\n",
    "    brainmask_inflated = np.where(brainmask_inflated==1.0, True, False)\n",
    "    mtl_mask = nib.load(f\"data/nsddata/ppdata/subj0{subject}/func1pt8mm/roi/MTL.nii.gz\").get_fdata()\n",
    "    mtl_mask = mtl_mask[brainmask_inflated]\n",
    "    with open(mtl_labels, 'r') as file:\n",
    "        labels = file.read().splitlines()\n",
    "    mtl_mask_labeled = {}\n",
    "    for label in labels[1:]:\n",
    "        label = label.split(\" \")\n",
    "        mtl_mask_labeled[label[1].strip()] = np.where(mtl_mask==int(label[0]), True, False)\n",
    "    return mtl_mask_labeled\n",
    "\n",
    "def get_streams_rois(subject, data_path):\n",
    "    streams_labels = f\"{data_path}/nsddata/freesurfer/subj0{subject}/label/streams.mgz.ctab\"\n",
    "    brainmask_inflated = nib.load(f\"{data_path}/nsddata/ppdata/subj0{subject}/func1pt8mm/roi/brainmask_inflated_1.0.nii\").get_fdata()\n",
    "    brainmask_inflated = np.nan_to_num(brainmask_inflated)\n",
    "    brainmask_inflated = np.where(brainmask_inflated==1.0, True, False)\n",
    "    streams_mask = nib.load(f\"{data_path}/nsddata/ppdata/subj0{subject}/func1pt8mm/roi/streams.nii.gz\").get_fdata()\n",
    "    streams_mask = streams_mask[brainmask_inflated]\n",
    "    with open(streams_labels, 'r') as file:\n",
    "        labels = file.read().splitlines()\n",
    "    streams_mask_labeled = {}\n",
    "    for label in labels[1:]:\n",
    "        label = label.split(\" \")\n",
    "        streams_mask_labeled[label[1].strip()] = np.where(streams_mask==int(label[0]), True, False)\n",
    "    nsd_general = nib.load(f\"{data_path}/nsddata/ppdata/subj0{subject}/func1pt8mm/roi/nsdgeneral.nii.gz\").get_fdata()\n",
    "    nsd_general = np.nan_to_num(nsd_general)\n",
    "    nsd_general = nsd_general[brainmask_inflated]\n",
    "    nsd_general = np.where(nsd_general==1.0, True, False)\n",
    "    streams_mask_labeled['nsd_general'] = nsd_general\n",
    "    return streams_mask_labeled\n",
    "\n",
    "def get_floc_rois(subject, data_path, floc_functionality='faces'):\n",
    "    floc_labels = f\"{data_path}/nsddata/freesurfer/subj0{subject}/label/floc-{floc_functionality}.mgz.ctab\"\n",
    "    brainmask_inflated = nib.load(f\"{data_path}/nsddata/ppdata/subj0{subject}/func1pt8mm/roi/brainmask_inflated_1.0.nii\").get_fdata()\n",
    "    brainmask_inflated = np.nan_to_num(brainmask_inflated)\n",
    "    brainmask_inflated = np.where(brainmask_inflated==1.0, True, False)\n",
    "    floc_mask = nib.load(f\"{data_path}/nsddata/ppdata/subj0{subject}/func1pt8mm/roi/floc-{floc_functionality}.nii.gz\").get_fdata()\n",
    "    floc_mask = floc_mask[brainmask_inflated]\n",
    "    with open(floc_labels, 'r') as file:\n",
    "        labels = file.read().splitlines()\n",
    "    floc_mask_labeled = {}\n",
    "    for label in labels[1:]:\n",
    "        label = label.split(\" \")\n",
    "        floc_mask_labeled[label[1].strip()] = np.where(floc_mask==int(label[0]), True, False)\n",
    "    return floc_mask_labeled\n",
    "\n",
    "# kastner_mask_labeled = get_kastner_rois(1, \"data/\")\n",
    "# print(kastner_mask_labeled.keys(), np.unique(kastner_mask_labeled['V1'], return_counts=True))\n",
    "\n",
    "# mm1_mask_labeled = get_hcp_mmp1_rois(1, \"data/\")\n",
    "# print(mm1_mask_labeled.keys(), np.unique(mm1_mask_labeled['V1'], return_counts=True))\n",
    "\n",
    "# thalamus_mask_labeled = get_thalamus_rois(1, \"data/\")\n",
    "# print(thalamus_mask_labeled.keys(), np.unique(thalamus_mask_labeled['LGN'], return_counts=True))\n",
    "\n",
    "# mtl_mask_labeled = get_mtl_rois(1, \"data/\")\n",
    "# print(mtl_mask_labeled.keys(), np.unique(mtl_mask_labeled['ERC'], return_counts=True))\n",
    "\n",
    "streams_mask_labeled = get_streams_rois(1, \"dataset/\")\n",
    "print(streams_mask_labeled.keys(), np.unique(streams_mask_labeled['ventral'], return_counts=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"/home/naxos2-raid25/kneel027/home/kneel027/data/mindeye_imagery/kastner_rois.hdf5\", 'w') as hdf:\n",
    "    for subject in range(1, 9):\n",
    "        subject_str = f\"subj{subject:02d}\"\n",
    "        mask_dictionary = get_kastner_masks(subject, \"data/\")\n",
    "\n",
    "        # Create a group for each subject\n",
    "        subject_group = hdf.create_group(subject_str)\n",
    "\n",
    "        # Iterate through the mask dictionary and create datasets for each mask\n",
    "        for region, mask in mask_dictionary.items():\n",
    "            subject_group.create_dataset(region, data=mask)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"/home/naxos2-raid25/kneel027/home/kneel027/data/mindeye_imagery/hcp_mmp1_rois.hdf5\", 'w') as hdf:\n",
    "    for subject in range(1, 9):\n",
    "        subject_str = f\"subj{subject:02d}\"\n",
    "        mask_dictionary = get_hcp_mmp1_rois(subject, \"data/\")\n",
    "\n",
    "        # Create a group for each subject\n",
    "        subject_group = hdf.create_group(subject_str)\n",
    "\n",
    "        # Iterate through the mask dictionary and create datasets for each mask\n",
    "        for region, mask in mask_dictionary.items():\n",
    "            subject_group.create_dataset(region, data=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"/home/naxos2-raid25/kneel027/home/kneel027/data/mindeye_imagery/thalamus_rois.hdf5\", 'w') as hdf:\n",
    "    for subject in range(1, 9):\n",
    "        subject_str = f\"subj{subject:02d}\"\n",
    "        mask_dictionary = get_thalamus_rois(subject, \"data/\")\n",
    "\n",
    "        # Create a group for each subject\n",
    "        subject_group = hdf.create_group(subject_str)\n",
    "\n",
    "        # Iterate through the mask dictionary and create datasets for each mask\n",
    "        for region, mask in mask_dictionary.items():\n",
    "            subject_group.create_dataset(region, data=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"/home/naxos2-raid25/kneel027/home/kneel027/data/mindeye_imagery/mtl_rois.hdf5\", 'w') as hdf:\n",
    "    for subject in range(1, 9):\n",
    "        subject_str = f\"subj{subject:02d}\"\n",
    "        mask_dictionary = get_mtl_rois(subject, \"data/\")\n",
    "\n",
    "        # Create a group for each subject\n",
    "        subject_group = hdf.create_group(subject_str)\n",
    "\n",
    "        # Iterate through the mask dictionary and create datasets for each mask\n",
    "        for region, mask in mask_dictionary.items():\n",
    "            subject_group.create_dataset(region, data=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"/home/naxos2-raid25/kneel027/home/kneel027/data/mindeye_imagery/streams_rois.hdf5\", 'w') as hdf:\n",
    "    for subject in range(1, 9):\n",
    "        subject_str = f\"subj{subject:02d}\"\n",
    "        mask_dictionary = get_streams_rois(subject, \"data/\")\n",
    "\n",
    "        # Create a group for each subject\n",
    "        subject_group = hdf.create_group(subject_str)\n",
    "\n",
    "        # Iterate through the mask dictionary and create datasets for each mask\n",
    "        for region, mask in mask_dictionary.items():\n",
    "            subject_group.create_dataset(region, data=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"/home/naxos2-raid25/ojeda040/local/ojeda040/MindEye_Imagery/dataset/floc_words_rois.hdf5\", 'w') as hdf:\n",
    "    for subject in range(1, 9):\n",
    "        subject_str = f\"subj{subject:02d}\"\n",
    "        mask_dictionary = get_floc_rois(subject, \"dataset/\", floc_functionality='words')\n",
    "\n",
    "        # Create a group for each subject\n",
    "        subject_group = hdf.create_group(subject_str)\n",
    "\n",
    "        # Iterate through the mask dictionary and create datasets for each mask\n",
    "        for region, mask in mask_dictionary.items():\n",
    "            subject_group.create_dataset(region, data=mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
