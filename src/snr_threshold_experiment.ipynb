{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0f0f4f3",
   "metadata": {},
   "source": [
    "# Import packages & functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bad764b-45c1-45ce-a716-8d055e09821a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import math\n",
    "from einops import rearrange\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import webdataset as wds\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from accelerate import Accelerator\n",
    "\n",
    "os.chdir(\"/home/naxos2-raid25/ojeda040/local/ojeda040/MindEye_Imagery/src\")\n",
    "\n",
    "# SDXL unCLIP requires code from https://github.com/Stability-AI/generative-models/tree/main\n",
    "sys.path.append('generative_models/')\n",
    "import sgm\n",
    "from models import Clipper\n",
    "from generative_models.sgm.modules.encoders.modules import FrozenOpenCLIPImageEmbedder # bigG embedder\n",
    "\n",
    "# tf32 data type is faster than standard float32\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# custom functions #\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2914864",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 1\n",
    "data_path = \"\"\n",
    "snr_threshold = 0.60\n",
    "betas = create_snr_betas(s, data_path, threshold = snr_threshold)\n",
    "betas = torch.Tensor(betas).to(\"cpu\").to(data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee225294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading raw scanning session data: 100%|██████████| 40/40 [12:20<00:00, 18.50s/it]\n"
     ]
    }
   ],
   "source": [
    "#create_whole_region_unnormalized(subject = 1, include_heldout=True, mask_nsd_general=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23b3a88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27000, 238508]) torch.Size([30000, 238508])\n"
     ]
    }
   ],
   "source": [
    "#create_whole_region_normalized(subject = 1, include_heldout=True, mask_nsd_general=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0763293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading samples:  89%|████████▉ | 26731/30000 [00:04<00:00, 7239.41it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([9000, 3, 238508])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack load_nsd\n",
    "current_directory = os.getcwd()\n",
    "subject = 1\n",
    "beta_file = f\"{current_directory}/data/preprocessed_data/subject01/whole_brain_include_heldout.pt\"\n",
    "#beta_file = \"/home/naxos2-raid25/ojeda040/local/ojeda040/MindEye_Imagery/src/data/preprocessed_data/subject1/nsd_general_include_heldout.pt\"\n",
    "x = torch.load(beta_file).requires_grad_(False).to(\"cpu\")\n",
    "stim_descriptions = pd.read_csv(\"/\".join(current_directory.split(\"/\")[:-1]) + \"/dataset/nsddata/experiments/nsd/nsd_stim_info_merged.csv\", index_col=0)\n",
    "subj_train = stim_descriptions[(stim_descriptions['subject{}'.format(subject)] != 0) & (stim_descriptions['shared1000'] == False)]\n",
    "subj_test = stim_descriptions[(stim_descriptions['subject{}'.format(subject)] != 0) & (stim_descriptions['shared1000'] == True)]\n",
    "test_trials = []\n",
    "test_sessions = []\n",
    "x_train = torch.zeros((9000, 3, x.shape[1])).to(\"cpu\")\n",
    "pbar = tqdm(desc=\"loading samples\", total=x.shape[0])\n",
    "\n",
    "# Collect the non-test data for the training set\n",
    "for i in range(subj_train.shape[0]):\n",
    "    for j in range(3):\n",
    "        scanId = subj_train.iloc[i]['subject{}_rep{}'.format(subject, j)] - 1\n",
    "        if(scanId < x.shape[0]):\n",
    "            x_train[i, j, :] = x[scanId]\n",
    "            pbar.update() \n",
    "            \n",
    "            \n",
    "x_train.shape\n",
    "# betas = [voxels, reps, samples]\n",
    "# torch.Size([9000, 3, 238508])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb8175e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading samples:  90%|█████████ | 27000/30000 [00:19<00:00, 7239.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR: tensor([0.3515, 0.3387, 0.3285,  ..., 0.3468, 0.3357, 0.3433])\n",
      "SIGNAL: tensor([0.3452, 0.3369, 0.3301,  ..., 0.3422, 0.3349, 0.3399])\n",
      "NOISE: tensor([0.9822, 0.9946, 1.0048,  ..., 0.9867, 0.9976, 0.9902])\n"
     ]
    }
   ],
   "source": [
    "# SNR Calulation\n",
    "snr, signal, noise = calculate_snr(x_train)\n",
    "print(f\"SNR: {snr}\")\n",
    "print(f\"SIGNAL: {signal}\")\n",
    "print(f\"NOISE: {noise}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "405272d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b4560be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2785)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading samples:  90%|█████████ | 27000/30000 [00:19<00:00, 13445.59it/s]"
     ]
    }
   ],
   "source": [
    "torch.max(snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19ac07ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30000, 238508])\n",
      "tensor([[ 6.3150e-01, -6.0554e-01, -4.2650e-01,  ...,  4.3917e-01,\n",
      "          1.9096e-03,  3.7853e-01],\n",
      "        [ 8.3171e-01,  1.0849e-01,  3.8990e-01,  ..., -3.4662e-01,\n",
      "         -1.0818e+00, -1.3847e-01],\n",
      "        [ 6.6918e-01,  6.7614e-01,  1.4183e+00,  ..., -4.8620e-01,\n",
      "         -6.9387e-01,  1.2925e+00],\n",
      "        ...,\n",
      "        [-2.2420e-01, -1.0643e+00, -3.4066e-01,  ..., -1.1105e-01,\n",
      "         -2.0496e+00, -5.7585e-01],\n",
      "        [ 2.1926e-01, -1.7885e+00, -6.4900e-01,  ...,  3.0040e-01,\n",
      "         -1.5414e+00, -1.3365e+00],\n",
      "        [ 8.7046e-01, -9.6213e-01, -1.7773e-01,  ..., -4.3053e-01,\n",
      "         -7.4684e-01, -2.9001e-01]])\n"
     ]
    }
   ],
   "source": [
    "condition = snr > .35\n",
    "snr_tensor = torch.where(condition, x, torch.tensor(0.0))\n",
    "print(snr_tensor.shape)\n",
    "\n",
    "snr_tensor_no_zeros = (snr_tensor != 0.0).any(dim=0)\n",
    "\n",
    "# Filter out the zero columns\n",
    "filtered_tensor = snr_tensor[:, snr_tensor_no_zeros]\n",
    "\n",
    "print(filtered_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "425d7b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30000, 102624])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ec4517-dbdf-4ece-98f6-4714d5de4e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {}\n",
    "train_dl = {}\n",
    "num_voxels = {}\n",
    "voxels = {}\n",
    "for s in subj_list:\n",
    "    print(f\"Training with {num_sessions} sessions\")\n",
    "    if s < 9:\n",
    "        if multi_subject:\n",
    "            train_url = f\"{data_path}/wds/subj{s:02d}/train/\" + \"{0..\" + f\"{nsessions_allsubj[s-1]-1}\" + \"}.tar\"\n",
    "        else:\n",
    "            train_url = f\"{data_path}/wds/subj{s:02d}/train/\" + \"{0..\" + f\"{num_sessions-1}\" + \"}.tar\"\n",
    "        print(train_url)\n",
    "        \n",
    "        train_data[f'subj{s:02d}'] = wds.WebDataset(train_url,resampled=True,nodesplitter=my_split_by_node)\\\n",
    "                            .shuffle(750, initial=1500, rng=random.Random(42))\\\n",
    "                            .decode(\"torch\")\\\n",
    "                            .rename(behav=\"behav.npy\", past_behav=\"past_behav.npy\", future_behav=\"future_behav.npy\", olds_behav=\"olds_behav.npy\")\\\n",
    "                            .to_tuple(*[\"behav\", \"past_behav\", \"future_behav\", \"olds_behav\"])\n",
    "        train_dl[f'subj{s:02d}'] = torch.utils.data.DataLoader(train_data[f'subj{s:02d}'], batch_size=batch_size, shuffle=False, drop_last=True, pin_memory=True)\n",
    "        betas = create_snr_betas(s, data_path, threshold = snr_threshold)\n",
    "        betas = torch.Tensor(betas).to(\"cpu\").to(data_type)\n",
    "        num_voxels_list.append(betas[0].shape[-1])\n",
    "        num_voxels[f'subj{s:02d}'] = betas[0].shape[-1]\n",
    "        voxels[f'subj{s:02d}'] = betas\n",
    "    elif s < 12:\n",
    "        train_url = \"\"\n",
    "        test_url = \"\"\n",
    "        betas, images, _, _ = utils.load_imageryrf(subject=int(s-8), mode=mode, mask=True, stimtype=\"object\", average=False, nest=False, split=True)\n",
    "        betas = torch.where(torch.isnan(betas), torch.zeros_like(betas), betas)\n",
    "        betas = betas.to(\"cpu\").to(data_type)\n",
    "        num_voxels_list.append(betas[0].shape[-1])\n",
    "        num_voxels[f'subj{s:02d}'] = betas[0].shape[-1]\n",
    "        num_nan_values = torch.sum(torch.isnan(betas))\n",
    "        print(\"Number of NaN values in betas:\", num_nan_values.item())\n",
    "        indices = torch.randperm(len(betas))\n",
    "        shuffled_betas = betas[indices]\n",
    "        shuffled_images = images[indices]\n",
    "        train_data[f'subj{s:02d}'] = torch.utils.data.TensorDataset(shuffled_betas, shuffled_images)\n",
    "        train_dl[f'subj{s:02d}'] = torch.utils.data.DataLoader(train_data[f'subj{s:02d}'], batch_size=batch_size, shuffle=False, drop_last=True, pin_memory=True)\n",
    "        \n",
    "        \n",
    "    # elif s < 15:\n",
    "    #     betas, images = utils.load_imageryrf(subject=int(s-11), mode=\"imagery\", mask=True, stimtype=\"object\", average=False, nest=False)\n",
    "    #     betas = torch.where(torch.isnan(betas), torch.zeros_like(betas), betas)\n",
    "    #     betas = betas.to(\"cpu\").to(data_type)\n",
    "    #     num_voxels_list.append(betas[0].shape[-1])\n",
    "    #     num_voxels[f'subj{s:02d}'] = betas[0].shape[-1]\n",
    "        \n",
    "    #     indices = torch.randperm(len(betas))\n",
    "    #     shuffled_betas = betas[indices]\n",
    "    #     shuffled_images = images[indices]\n",
    "    #     train_data[f'subj{s:02d}'] = torch.utils.data.TensorDataset(shuffled_betas, shuffled_images)\n",
    "    #     train_dl[f'subj{s:02d}'] = torch.utils.data.DataLoader(train_data[f'subj{s:02d}'], batch_size=batch_size, shuffle=False, drop_last=True, pin_memory=True)\n",
    "    print(f\"num_voxels for subj{s:02d}: {num_voxels[f'subj{s:02d}']}\")\n",
    "\n",
    "print(\"Loaded all subj train dls and betas!\\n\")\n",
    "\n",
    "# Validate only on one subject (doesn't support ImageryRF)\n",
    "if multi_subject: \n",
    "    subj = subj_list[0] # cant validate on the actual held out person so picking first in subj_list\n",
    "if not new_test: # using old test set from before full dataset released (used in original MindEye paper)\n",
    "    if subj==3:\n",
    "        num_test=2113\n",
    "    elif subj==4:\n",
    "        num_test=1985\n",
    "    elif subj==6:\n",
    "        num_test=2113\n",
    "    elif subj==8:\n",
    "        num_test=1985\n",
    "    else:\n",
    "        num_test=2770\n",
    "    test_url = f\"{data_path}/wds/subj0{subj}/test/\" + \"0.tar\"\n",
    "elif new_test: # using larger test set from after full dataset released\n",
    "    if subj==3:\n",
    "        num_test=2371\n",
    "    elif subj==4:\n",
    "        num_test=2188\n",
    "    elif subj==6:\n",
    "        num_test=2371\n",
    "    elif subj==8:\n",
    "        num_test=2188\n",
    "    else:\n",
    "        num_test=3000\n",
    "    test_url = f\"{data_path}/wds/subj0{subj}/new_test/\" + \"0.tar\"\n",
    "print(test_url)\n",
    "if subj < 9:\n",
    "    test_data = wds.WebDataset(test_url,resampled=False,nodesplitter=my_split_by_node)\\\n",
    "                        .shuffle(750, initial=1500, rng=random.Random(42))\\\n",
    "                        .decode(\"torch\")\\\n",
    "                        .rename(behav=\"behav.npy\", past_behav=\"past_behav.npy\", future_behav=\"future_behav.npy\", olds_behav=\"olds_behav.npy\")\\\n",
    "                        .to_tuple(*[\"behav\", \"past_behav\", \"future_behav\", \"olds_behav\"])\n",
    "    test_dl = torch.utils.data.DataLoader(test_data, batch_size=num_test, shuffle=False, drop_last=True, pin_memory=True)\n",
    "else:\n",
    "    _, _, betas, images = utils.load_imageryrf(subject=int(subj-8), mode=mode, mask=True, stimtype=\"object\", average=False, nest=True, split=True)\n",
    "    num_test = len(betas)\n",
    "    betas = torch.where(torch.isnan(betas), torch.zeros_like(betas), betas)\n",
    "    betas = betas.to(\"cpu\").to(data_type)\n",
    "    num_nan_values = torch.sum(torch.isnan(betas))\n",
    "    print(\"Number of NaN values in test betas:\", num_nan_values.item())\n",
    "    test_data = torch.utils.data.TensorDataset(betas, images)\n",
    "    test_dl = torch.utils.data.DataLoader(test_data, batch_size=num_test, shuffle=False, drop_last=True, pin_memory=True)\n",
    "print(f\"Loaded test dl for subj{subj}!\\n\")\n",
    "\n",
    "seq_len = seq_past + 1 + seq_future\n",
    "print(f\"currently using {seq_len} seq_len (chose {seq_past} past behav and {seq_future} future behav)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "62aae01ef0cf7b6af841ab1c8ce59175c4332e693ab3d00bc32ceffb78a35376"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
