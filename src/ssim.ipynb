{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f12f2fd-9c88-47f5-b687-2feec6fede8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import mean_squared_error\n",
    "from skimage import img_as_float\n",
    "\n",
    "def calculate_metrics(directory1, directory2, image_count=30000, standard_size=(512, 512), win_size=3):\n",
    "    ssim_scores = []\n",
    "    mse_scores=[]\n",
    "\n",
    "    # Check if both directories have exactly 30000 images\n",
    "    if len(os.listdir(directory1)) != image_count or len(os.listdir(directory2)) != image_count:\n",
    "        raise ValueError(\"Both directories must contain exactly 30,000 images.\")\n",
    "\n",
    "    for i in tqdm(range(image_count), desc=\"Calculating SSIM\"):\n",
    "        img_name = f'img{i}.jpg'\n",
    "        img_path1 = os.path.join(directory1, img_name)\n",
    "        img_path2 = os.path.join(directory2, img_name)\n",
    "\n",
    "        if not os.path.isfile(img_path1) or not os.path.isfile(img_path2):\n",
    "            raise FileNotFoundError(f\"Image {img_name} not found in one of the directories.\")\n",
    "\n",
    "        # Load and process images\n",
    "        image1 = cv2.imread(img_path1)\n",
    "        image2 = cv2.imread(img_path2)\n",
    "\n",
    "        # Resize images\n",
    "        image1 = cv2.resize(image1, standard_size)\n",
    "        image2 = cv2.resize(image2, standard_size)\n",
    "\n",
    "        # Compute SSIM between two images\n",
    "        mse = mean_squared_error(image1, image2)\n",
    "        score = ssim(image1, image2, multichannel=True, win_size=win_size)\n",
    "        ssim_scores.append(score)\n",
    "        mse_scores.append(mse)\n",
    "\n",
    "    # Compute average SSIM\n",
    "    average_ssim = np.mean(ssim_scores)\n",
    "    average_mse = np.mean(mse_scores)\n",
    "    return average_ssim,average_mse\n",
    "\n",
    "# Directories containing your images\n",
    "real_images_dir = '/weka/proj-fmri/shared/coco/sampled_imgs'\n",
    "generated_images_dir = '/weka/proj-fmri/shared/coco/xlunclip_imgs'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55242194-908e-45f9-ad4d-8714a1872331",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating SSIM: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30000/30000 [1:16:31<00:00,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average SSIM: 0.23631854792393547\n",
      "Average MSE: 10188.122414026855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "average_ssim, average_mse = calculate_metrics(real_images_dir, generated_images_dir)\n",
    "print(f'Average SSIM: {average_ssim}')\n",
    "print(f'Average MSE: {average_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cccace8-a092-4eb2-b179-69cfbca07255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating SSIM: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30000/30000 [2:03:50<00:00,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average SSIM: 0.4762611792756796\n",
      "Average MSE: 3880.7134732752484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "average_ssim, average_mse = calculate_metrics(real_images_dir, generated_images_dir)\n",
    "print(f'Average SSIM: {average_ssim}')\n",
    "print(f'Average MSE: {average_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aacc95c-4e46-4626-ad63-6ca9edd25d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45892bb3-1694-4be9-932f-ea8df767d3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['module', 'buffer_names', 'optimizer', 'param_shapes', 'frozen_param_shapes', 'shared_params', 'frozen_param_fragments', 'lr_scheduler', 'data_sampler', 'random_ltd', 'sparse_tensor_module_names', 'skipped_steps', 'global_steps', 'global_samples', 'dp_world_size', 'mp_world_size', 'ds_config', 'ds_version'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.load(\"\")\n",
    "x.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f595ac2-063f-4fbd-9c5b-ecf6d1a89d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['ridge.linears.0.weight', 'ridge.linears.0.bias', 'backbone.mixer_blocks1.0.0.weight', 'backbone.mixer_blocks1.0.0.bias', 'backbone.mixer_blocks1.0.1.0.weight', 'backbone.mixer_blocks1.0.1.0.bias', 'backbone.mixer_blocks1.0.1.3.weight', 'backbone.mixer_blocks1.0.1.3.bias', 'backbone.mixer_blocks1.1.0.weight', 'backbone.mixer_blocks1.1.0.bias', 'backbone.mixer_blocks1.1.1.0.weight', 'backbone.mixer_blocks1.1.1.0.bias', 'backbone.mixer_blocks1.1.1.3.weight', 'backbone.mixer_blocks1.1.1.3.bias', 'backbone.mixer_blocks1.2.0.weight', 'backbone.mixer_blocks1.2.0.bias', 'backbone.mixer_blocks1.2.1.0.weight', 'backbone.mixer_blocks1.2.1.0.bias', 'backbone.mixer_blocks1.2.1.3.weight', 'backbone.mixer_blocks1.2.1.3.bias', 'backbone.mixer_blocks1.3.0.weight', 'backbone.mixer_blocks1.3.0.bias', 'backbone.mixer_blocks1.3.1.0.weight', 'backbone.mixer_blocks1.3.1.0.bias', 'backbone.mixer_blocks1.3.1.3.weight', 'backbone.mixer_blocks1.3.1.3.bias', 'backbone.mixer_blocks2.0.0.weight', 'backbone.mixer_blocks2.0.0.bias', 'backbone.mixer_blocks2.0.1.0.weight', 'backbone.mixer_blocks2.0.1.0.bias', 'backbone.mixer_blocks2.0.1.3.weight', 'backbone.mixer_blocks2.0.1.3.bias', 'backbone.mixer_blocks2.1.0.weight', 'backbone.mixer_blocks2.1.0.bias', 'backbone.mixer_blocks2.1.1.0.weight', 'backbone.mixer_blocks2.1.1.0.bias', 'backbone.mixer_blocks2.1.1.3.weight', 'backbone.mixer_blocks2.1.1.3.bias', 'backbone.mixer_blocks2.2.0.weight', 'backbone.mixer_blocks2.2.0.bias', 'backbone.mixer_blocks2.2.1.0.weight', 'backbone.mixer_blocks2.2.1.0.bias', 'backbone.mixer_blocks2.2.1.3.weight', 'backbone.mixer_blocks2.2.1.3.bias', 'backbone.mixer_blocks2.3.0.weight', 'backbone.mixer_blocks2.3.0.bias', 'backbone.mixer_blocks2.3.1.0.weight', 'backbone.mixer_blocks2.3.1.0.bias', 'backbone.mixer_blocks2.3.1.3.weight', 'backbone.mixer_blocks2.3.1.3.bias', 'backbone.backbone_linear.weight', 'backbone.backbone_linear.bias', 'backbone.clip_proj.0.weight', 'backbone.clip_proj.0.bias', 'backbone.clip_proj.2.weight', 'backbone.clip_proj.2.bias', 'backbone.clip_proj.3.weight', 'backbone.clip_proj.3.bias', 'backbone.clip_proj.5.weight', 'backbone.clip_proj.5.bias', 'backbone.clip_proj.6.weight', 'backbone.clip_proj.6.bias', 'backbone.clip_proj.8.weight', 'backbone.clip_proj.8.bias', 'backbone.blin1.weight', 'backbone.blin1.bias', 'backbone.bnorm.weight', 'backbone.bnorm.bias', 'backbone.bupsampler.conv_in.weight', 'backbone.bupsampler.conv_in.bias', 'backbone.bupsampler.up_blocks.0.resnets.0.norm1.weight', 'backbone.bupsampler.up_blocks.0.resnets.0.norm1.bias', 'backbone.bupsampler.up_blocks.0.resnets.0.conv1.weight', 'backbone.bupsampler.up_blocks.0.resnets.0.conv1.bias', 'backbone.bupsampler.up_blocks.0.resnets.0.norm2.weight', 'backbone.bupsampler.up_blocks.0.resnets.0.norm2.bias', 'backbone.bupsampler.up_blocks.0.resnets.0.conv2.weight', 'backbone.bupsampler.up_blocks.0.resnets.0.conv2.bias', 'backbone.bupsampler.up_blocks.0.resnets.1.norm1.weight', 'backbone.bupsampler.up_blocks.0.resnets.1.norm1.bias', 'backbone.bupsampler.up_blocks.0.resnets.1.conv1.weight', 'backbone.bupsampler.up_blocks.0.resnets.1.conv1.bias', 'backbone.bupsampler.up_blocks.0.resnets.1.norm2.weight', 'backbone.bupsampler.up_blocks.0.resnets.1.norm2.bias', 'backbone.bupsampler.up_blocks.0.resnets.1.conv2.weight', 'backbone.bupsampler.up_blocks.0.resnets.1.conv2.bias', 'backbone.bupsampler.up_blocks.0.upsamplers.0.conv.weight', 'backbone.bupsampler.up_blocks.0.upsamplers.0.conv.bias', 'backbone.bupsampler.up_blocks.1.resnets.0.norm1.weight', 'backbone.bupsampler.up_blocks.1.resnets.0.norm1.bias', 'backbone.bupsampler.up_blocks.1.resnets.0.conv1.weight', 'backbone.bupsampler.up_blocks.1.resnets.0.conv1.bias', 'backbone.bupsampler.up_blocks.1.resnets.0.norm2.weight', 'backbone.bupsampler.up_blocks.1.resnets.0.norm2.bias', 'backbone.bupsampler.up_blocks.1.resnets.0.conv2.weight', 'backbone.bupsampler.up_blocks.1.resnets.0.conv2.bias', 'backbone.bupsampler.up_blocks.1.resnets.0.conv_shortcut.weight', 'backbone.bupsampler.up_blocks.1.resnets.0.conv_shortcut.bias', 'backbone.bupsampler.up_blocks.1.resnets.1.norm1.weight', 'backbone.bupsampler.up_blocks.1.resnets.1.norm1.bias', 'backbone.bupsampler.up_blocks.1.resnets.1.conv1.weight', 'backbone.bupsampler.up_blocks.1.resnets.1.conv1.bias', 'backbone.bupsampler.up_blocks.1.resnets.1.norm2.weight', 'backbone.bupsampler.up_blocks.1.resnets.1.norm2.bias', 'backbone.bupsampler.up_blocks.1.resnets.1.conv2.weight', 'backbone.bupsampler.up_blocks.1.resnets.1.conv2.bias', 'backbone.bupsampler.up_blocks.1.upsamplers.0.conv.weight', 'backbone.bupsampler.up_blocks.1.upsamplers.0.conv.bias', 'backbone.bupsampler.up_blocks.2.resnets.0.norm1.weight', 'backbone.bupsampler.up_blocks.2.resnets.0.norm1.bias', 'backbone.bupsampler.up_blocks.2.resnets.0.conv1.weight', 'backbone.bupsampler.up_blocks.2.resnets.0.conv1.bias', 'backbone.bupsampler.up_blocks.2.resnets.0.norm2.weight', 'backbone.bupsampler.up_blocks.2.resnets.0.norm2.bias', 'backbone.bupsampler.up_blocks.2.resnets.0.conv2.weight', 'backbone.bupsampler.up_blocks.2.resnets.0.conv2.bias', 'backbone.bupsampler.up_blocks.2.resnets.0.conv_shortcut.weight', 'backbone.bupsampler.up_blocks.2.resnets.0.conv_shortcut.bias', 'backbone.bupsampler.up_blocks.2.resnets.1.norm1.weight', 'backbone.bupsampler.up_blocks.2.resnets.1.norm1.bias', 'backbone.bupsampler.up_blocks.2.resnets.1.conv1.weight', 'backbone.bupsampler.up_blocks.2.resnets.1.conv1.bias', 'backbone.bupsampler.up_blocks.2.resnets.1.norm2.weight', 'backbone.bupsampler.up_blocks.2.resnets.1.norm2.bias', 'backbone.bupsampler.up_blocks.2.resnets.1.conv2.weight', 'backbone.bupsampler.up_blocks.2.resnets.1.conv2.bias', 'backbone.bupsampler.mid_block.attentions.0.group_norm.weight', 'backbone.bupsampler.mid_block.attentions.0.group_norm.bias', 'backbone.bupsampler.mid_block.attentions.0.query.weight', 'backbone.bupsampler.mid_block.attentions.0.query.bias', 'backbone.bupsampler.mid_block.attentions.0.key.weight', 'backbone.bupsampler.mid_block.attentions.0.key.bias', 'backbone.bupsampler.mid_block.attentions.0.value.weight', 'backbone.bupsampler.mid_block.attentions.0.value.bias', 'backbone.bupsampler.mid_block.attentions.0.proj_attn.weight', 'backbone.bupsampler.mid_block.attentions.0.proj_attn.bias', 'backbone.bupsampler.mid_block.resnets.0.norm1.weight', 'backbone.bupsampler.mid_block.resnets.0.norm1.bias', 'backbone.bupsampler.mid_block.resnets.0.conv1.weight', 'backbone.bupsampler.mid_block.resnets.0.conv1.bias', 'backbone.bupsampler.mid_block.resnets.0.norm2.weight', 'backbone.bupsampler.mid_block.resnets.0.norm2.bias', 'backbone.bupsampler.mid_block.resnets.0.conv2.weight', 'backbone.bupsampler.mid_block.resnets.0.conv2.bias', 'backbone.bupsampler.mid_block.resnets.1.norm1.weight', 'backbone.bupsampler.mid_block.resnets.1.norm1.bias', 'backbone.bupsampler.mid_block.resnets.1.conv1.weight', 'backbone.bupsampler.mid_block.resnets.1.conv1.bias', 'backbone.bupsampler.mid_block.resnets.1.norm2.weight', 'backbone.bupsampler.mid_block.resnets.1.norm2.bias', 'backbone.bupsampler.mid_block.resnets.1.conv2.weight', 'backbone.bupsampler.mid_block.resnets.1.conv2.bias', 'backbone.bupsampler.conv_norm_out.weight', 'backbone.bupsampler.conv_norm_out.bias', 'backbone.bupsampler.conv_out.weight', 'backbone.bupsampler.conv_out.bias', 'backbone.b_maps_projector.0.weight', 'backbone.b_maps_projector.1.weight', 'backbone.b_maps_projector.1.bias', 'backbone.b_maps_projector.3.weight', 'backbone.b_maps_projector.4.weight', 'backbone.b_maps_projector.4.bias', 'backbone.b_maps_projector.6.weight', 'backbone.b_maps_projector.6.bias', 'diffusion_prior.noise_scheduler.betas', 'diffusion_prior.noise_scheduler.alphas_cumprod', 'diffusion_prior.noise_scheduler.alphas_cumprod_prev', 'diffusion_prior.noise_scheduler.sqrt_alphas_cumprod', 'diffusion_prior.noise_scheduler.sqrt_one_minus_alphas_cumprod', 'diffusion_prior.noise_scheduler.log_one_minus_alphas_cumprod', 'diffusion_prior.noise_scheduler.sqrt_recip_alphas_cumprod', 'diffusion_prior.noise_scheduler.sqrt_recipm1_alphas_cumprod', 'diffusion_prior.noise_scheduler.posterior_variance', 'diffusion_prior.noise_scheduler.posterior_log_variance_clipped', 'diffusion_prior.noise_scheduler.posterior_mean_coef1', 'diffusion_prior.noise_scheduler.posterior_mean_coef2', 'diffusion_prior.noise_scheduler.p2_loss_weight', 'diffusion_prior.net.learned_query', 'diffusion_prior.net.null_brain_embeds', 'diffusion_prior.net.null_image_embed', 'diffusion_prior.net.to_time_embeds.0.1.net.0.0.weight', 'diffusion_prior.net.to_time_embeds.0.1.net.0.0.bias', 'diffusion_prior.net.to_time_embeds.0.1.net.1.0.weight', 'diffusion_prior.net.to_time_embeds.0.1.net.1.0.bias', 'diffusion_prior.net.to_time_embeds.0.1.net.2.weight', 'diffusion_prior.net.to_time_embeds.0.1.net.2.bias', 'diffusion_prior.net.causal_transformer.rel_pos_bias.relative_attention_bias.weight', 'diffusion_prior.net.causal_transformer.layers.0.0.null_kv', 'diffusion_prior.net.causal_transformer.layers.0.0.norm.g', 'diffusion_prior.net.causal_transformer.layers.0.0.to_q.weight', 'diffusion_prior.net.causal_transformer.layers.0.0.to_kv.weight', 'diffusion_prior.net.causal_transformer.layers.0.0.rotary_emb.freqs', 'diffusion_prior.net.causal_transformer.layers.0.0.to_out.0.weight', 'diffusion_prior.net.causal_transformer.layers.0.0.to_out.1.g', 'diffusion_prior.net.causal_transformer.layers.0.1.0.g', 'diffusion_prior.net.causal_transformer.layers.0.1.1.weight', 'diffusion_prior.net.causal_transformer.layers.0.1.5.weight', 'diffusion_prior.net.causal_transformer.layers.1.0.null_kv', 'diffusion_prior.net.causal_transformer.layers.1.0.norm.g', 'diffusion_prior.net.causal_transformer.layers.1.0.to_q.weight', 'diffusion_prior.net.causal_transformer.layers.1.0.to_kv.weight', 'diffusion_prior.net.causal_transformer.layers.1.0.rotary_emb.freqs', 'diffusion_prior.net.causal_transformer.layers.1.0.to_out.0.weight', 'diffusion_prior.net.causal_transformer.layers.1.0.to_out.1.g', 'diffusion_prior.net.causal_transformer.layers.1.1.0.g', 'diffusion_prior.net.causal_transformer.layers.1.1.1.weight', 'diffusion_prior.net.causal_transformer.layers.1.1.5.weight', 'diffusion_prior.net.causal_transformer.layers.2.0.null_kv', 'diffusion_prior.net.causal_transformer.layers.2.0.norm.g', 'diffusion_prior.net.causal_transformer.layers.2.0.to_q.weight', 'diffusion_prior.net.causal_transformer.layers.2.0.to_kv.weight', 'diffusion_prior.net.causal_transformer.layers.2.0.rotary_emb.freqs', 'diffusion_prior.net.causal_transformer.layers.2.0.to_out.0.weight', 'diffusion_prior.net.causal_transformer.layers.2.0.to_out.1.g', 'diffusion_prior.net.causal_transformer.layers.2.1.0.g', 'diffusion_prior.net.causal_transformer.layers.2.1.1.weight', 'diffusion_prior.net.causal_transformer.layers.2.1.5.weight', 'diffusion_prior.net.causal_transformer.layers.3.0.null_kv', 'diffusion_prior.net.causal_transformer.layers.3.0.norm.g', 'diffusion_prior.net.causal_transformer.layers.3.0.to_q.weight', 'diffusion_prior.net.causal_transformer.layers.3.0.to_kv.weight', 'diffusion_prior.net.causal_transformer.layers.3.0.rotary_emb.freqs', 'diffusion_prior.net.causal_transformer.layers.3.0.to_out.0.weight', 'diffusion_prior.net.causal_transformer.layers.3.0.to_out.1.g', 'diffusion_prior.net.causal_transformer.layers.3.1.0.g', 'diffusion_prior.net.causal_transformer.layers.3.1.1.weight', 'diffusion_prior.net.causal_transformer.layers.3.1.5.weight', 'diffusion_prior.net.causal_transformer.layers.4.0.null_kv', 'diffusion_prior.net.causal_transformer.layers.4.0.norm.g', 'diffusion_prior.net.causal_transformer.layers.4.0.to_q.weight', 'diffusion_prior.net.causal_transformer.layers.4.0.to_kv.weight', 'diffusion_prior.net.causal_transformer.layers.4.0.rotary_emb.freqs', 'diffusion_prior.net.causal_transformer.layers.4.0.to_out.0.weight', 'diffusion_prior.net.causal_transformer.layers.4.0.to_out.1.g', 'diffusion_prior.net.causal_transformer.layers.4.1.0.g', 'diffusion_prior.net.causal_transformer.layers.4.1.1.weight', 'diffusion_prior.net.causal_transformer.layers.4.1.5.weight', 'diffusion_prior.net.causal_transformer.layers.5.0.null_kv', 'diffusion_prior.net.causal_transformer.layers.5.0.norm.g', 'diffusion_prior.net.causal_transformer.layers.5.0.to_q.weight', 'diffusion_prior.net.causal_transformer.layers.5.0.to_kv.weight', 'diffusion_prior.net.causal_transformer.layers.5.0.rotary_emb.freqs', 'diffusion_prior.net.causal_transformer.layers.5.0.to_out.0.weight', 'diffusion_prior.net.causal_transformer.layers.5.0.to_out.1.g', 'diffusion_prior.net.causal_transformer.layers.5.1.0.g', 'diffusion_prior.net.causal_transformer.layers.5.1.1.weight', 'diffusion_prior.net.causal_transformer.layers.5.1.5.weight', 'diffusion_prior.net.causal_transformer.norm.g', 'diffusion_prior.net.causal_transformer.project_out.weight'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"module\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145129f9-7189-4502-9136-22dcb6af2230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
